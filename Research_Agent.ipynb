{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNlGBZscFVBsy9lPUz+iSAd"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<h1 align=\"center\">üìò Research Agent Analyst</h1>\n",
        "\n",
        "<p align=\"center\">\n",
        "A fully automated AI agent that reads research PDFs, extracts and restructures\n",
        "their content, builds context, summarizes them in a student-friendly way, and\n",
        "evaluates the output for clarity and correctness ‚Äî all using Vertex AI and\n",
        "Google‚Äôs Agent Development Kit (ADK).\n",
        "</p>\n"
      ],
      "metadata": {
        "id": "PWI0vS26jm7e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üîß Environment Setup\n",
        "Before building our research agent, we must install all required Google ADK and\n",
        "Vertex AI packages. These libraries allow our notebook to deploy agents, interact\n",
        "with the Reasoning Engine, and process PDFs.  \n",
        "This section ensures your environment has all the dependencies needed for the\n",
        "rest of the pipeline.\n"
      ],
      "metadata": {
        "id": "n6FFIQH9lBgq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "x64QXd1iAyr1",
        "outputId": "9aa25f95-af9d-4194-b8de-4f2da9ac5a2c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: google-adk in /usr/local/lib/python3.12/dist-packages (1.17.0)\n",
            "Collecting google-adk\n",
            "  Downloading google_adk-1.18.0-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: PyYAML<7.0.0,>=6.0.2 in /usr/local/lib/python3.12/dist-packages (from google-adk) (6.0.3)\n",
            "Requirement already satisfied: anyio<5.0.0,>=4.9.0 in /usr/local/lib/python3.12/dist-packages (from google-adk) (4.11.0)\n",
            "Requirement already satisfied: authlib<2.0.0,>=1.5.1 in /usr/local/lib/python3.12/dist-packages (from google-adk) (1.6.5)\n",
            "Requirement already satisfied: click<9.0.0,>=8.1.8 in /usr/local/lib/python3.12/dist-packages (from google-adk) (8.3.0)\n",
            "Requirement already satisfied: fastapi<1.119.0,>=0.115.0 in /usr/local/lib/python3.12/dist-packages (from google-adk) (0.121.1)\n",
            "Requirement already satisfied: google-api-python-client<3.0.0,>=2.157.0 in /usr/local/lib/python3.12/dist-packages (from google-adk) (2.187.0)\n",
            "Requirement already satisfied: google-cloud-aiplatform<2.0.0,>=1.125.0 in /usr/local/lib/python3.12/dist-packages (from google-cloud-aiplatform[agent-engines]<2.0.0,>=1.125.0->google-adk) (1.126.1)\n",
            "Requirement already satisfied: google-cloud-bigtable>=2.32.0 in /usr/local/lib/python3.12/dist-packages (from google-adk) (2.34.0)\n",
            "Requirement already satisfied: google-cloud-discoveryengine<0.14.0,>=0.13.12 in /usr/local/lib/python3.12/dist-packages (from google-adk) (0.13.12)\n",
            "Requirement already satisfied: google-cloud-secret-manager<3.0.0,>=2.22.0 in /usr/local/lib/python3.12/dist-packages (from google-adk) (2.25.0)\n",
            "Requirement already satisfied: google-cloud-spanner<4.0.0,>=3.56.0 in /usr/local/lib/python3.12/dist-packages (from google-adk) (3.59.0)\n",
            "Requirement already satisfied: google-cloud-speech<3.0.0,>=2.30.0 in /usr/local/lib/python3.12/dist-packages (from google-adk) (2.34.0)\n",
            "Collecting google-cloud-storage<4.0.0,>=3.0.0 (from google-adk)\n",
            "  Downloading google_cloud_storage-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: google-genai<2.0.0,>=1.45.0 in /usr/local/lib/python3.12/dist-packages (from google-adk) (1.49.0)\n",
            "Requirement already satisfied: graphviz<1.0.0,>=0.20.2 in /usr/local/lib/python3.12/dist-packages (from google-adk) (0.21)\n",
            "Requirement already satisfied: mcp<2.0.0,>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from google-adk) (1.21.0)\n",
            "Requirement already satisfied: opentelemetry-api<=1.37.0,>=1.37.0 in /usr/local/lib/python3.12/dist-packages (from google-adk) (1.37.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-gcp-logging<2.0.0,>=1.9.0a0 in /usr/local/lib/python3.12/dist-packages (from google-adk) (1.11.0a0)\n",
            "Requirement already satisfied: opentelemetry-exporter-gcp-monitoring<2.0.0,>=1.9.0a0 in /usr/local/lib/python3.12/dist-packages (from google-adk) (1.11.0a0)\n",
            "Requirement already satisfied: opentelemetry-exporter-gcp-trace<2.0.0,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from google-adk) (1.11.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-http>=1.36.0 in /usr/local/lib/python3.12/dist-packages (from google-adk) (1.37.0)\n",
            "Requirement already satisfied: opentelemetry-resourcedetector-gcp<2.0.0,>=1.9.0a0 in /usr/local/lib/python3.12/dist-packages (from google-adk) (1.11.0a0)\n",
            "Requirement already satisfied: opentelemetry-sdk<=1.37.0,>=1.37.0 in /usr/local/lib/python3.12/dist-packages (from google-adk) (1.37.0)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.0 in /usr/local/lib/python3.12/dist-packages (from google-adk) (2.11.10)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.9.0.post0 in /usr/local/lib/python3.12/dist-packages (from google-adk) (2.9.0.post0)\n",
            "Requirement already satisfied: python-dotenv<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from google-adk) (1.2.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.32.4 in /usr/local/lib/python3.12/dist-packages (from google-adk) (2.32.4)\n",
            "Requirement already satisfied: sqlalchemy-spanner>=1.14.0 in /usr/local/lib/python3.12/dist-packages (from google-adk) (1.17.1)\n",
            "Requirement already satisfied: sqlalchemy<3.0.0,>=2.0 in /usr/local/lib/python3.12/dist-packages (from google-adk) (2.0.44)\n",
            "Requirement already satisfied: starlette<1.0.0,>=0.46.2 in /usr/local/lib/python3.12/dist-packages (from google-adk) (0.49.3)\n",
            "Collecting tenacity<10.0.0,>=9.0.0 (from google-adk)\n",
            "  Downloading tenacity-9.1.2-py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.5 in /usr/local/lib/python3.12/dist-packages (from google-adk) (4.15.0)\n",
            "Requirement already satisfied: tzlocal<6.0,>=5.3 in /usr/local/lib/python3.12/dist-packages (from google-adk) (5.3.1)\n",
            "Requirement already satisfied: uvicorn<1.0.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from google-adk) (0.38.0)\n",
            "Requirement already satisfied: watchdog<7.0.0,>=6.0.0 in /usr/local/lib/python3.12/dist-packages (from google-adk) (6.0.0)\n",
            "Requirement already satisfied: websockets<16.0.0,>=15.0.1 in /usr/local/lib/python3.12/dist-packages (from google-adk) (15.0.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0.0,>=4.9.0->google-adk) (3.11)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0.0,>=4.9.0->google-adk) (1.3.1)\n",
            "Requirement already satisfied: cryptography in /usr/local/lib/python3.12/dist-packages (from authlib<2.0.0,>=1.5.1->google-adk) (43.0.3)\n",
            "Requirement already satisfied: annotated-doc>=0.0.2 in /usr/local/lib/python3.12/dist-packages (from fastapi<1.119.0,>=0.115.0->google-adk) (0.0.4)\n",
            "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client<3.0.0,>=2.157.0->google-adk) (0.31.0)\n",
            "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client<3.0.0,>=2.157.0->google-adk) (2.38.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client<3.0.0,>=2.157.0->google-adk) (0.2.1)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client<3.0.0,>=2.157.0->google-adk) (2.28.1)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client<3.0.0,>=2.157.0->google-adk) (4.2.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.12/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.125.0->google-cloud-aiplatform[agent-engines]<2.0.0,>=1.125.0->google-adk) (1.26.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in /usr/local/lib/python3.12/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.125.0->google-cloud-aiplatform[agent-engines]<2.0.0,>=1.125.0->google-adk) (5.29.5)\n",
            "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.12/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.125.0->google-cloud-aiplatform[agent-engines]<2.0.0,>=1.125.0->google-adk) (25.0)\n",
            "Requirement already satisfied: google-cloud-bigquery!=3.20.0,<4.0.0,>=1.15.0 in /usr/local/lib/python3.12/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.125.0->google-cloud-aiplatform[agent-engines]<2.0.0,>=1.125.0->google-adk) (3.38.0)\n",
            "Requirement already satisfied: google-cloud-resource-manager<3.0.0,>=1.3.3 in /usr/local/lib/python3.12/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.125.0->google-cloud-aiplatform[agent-engines]<2.0.0,>=1.125.0->google-adk) (1.15.0)\n",
            "Requirement already satisfied: shapely<3.0.0 in /usr/local/lib/python3.12/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.125.0->google-cloud-aiplatform[agent-engines]<2.0.0,>=1.125.0->google-adk) (2.1.2)\n",
            "Requirement already satisfied: docstring_parser<1 in /usr/local/lib/python3.12/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.125.0->google-cloud-aiplatform[agent-engines]<2.0.0,>=1.125.0->google-adk) (0.17.0)\n",
            "Requirement already satisfied: cloudpickle<4.0,>=3.0 in /usr/local/lib/python3.12/dist-packages (from google-cloud-aiplatform[agent-engines]<2.0.0,>=1.125.0->google-adk) (3.1.2)\n",
            "Requirement already satisfied: google-cloud-trace<2 in /usr/local/lib/python3.12/dist-packages (from google-cloud-aiplatform[agent-engines]<2.0.0,>=1.125.0->google-adk) (1.17.0)\n",
            "Requirement already satisfied: google-cloud-logging<4 in /usr/local/lib/python3.12/dist-packages (from google-cloud-aiplatform[agent-engines]<2.0.0,>=1.125.0->google-adk) (3.12.1)\n",
            "Requirement already satisfied: google-cloud-core<3.0.0,>=1.4.4 in /usr/local/lib/python3.12/dist-packages (from google-cloud-bigtable>=2.32.0->google-adk) (2.5.0)\n",
            "Requirement already satisfied: grpc-google-iam-v1<1.0.0,>=0.12.4 in /usr/local/lib/python3.12/dist-packages (from google-cloud-bigtable>=2.32.0->google-adk) (0.14.3)\n",
            "Requirement already satisfied: google-crc32c<2.0.0dev,>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from google-cloud-bigtable>=2.32.0->google-adk) (1.7.1)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-cloud-secret-manager<3.0.0,>=2.22.0->google-adk) (1.76.0)\n",
            "Requirement already satisfied: sqlparse>=0.4.4 in /usr/local/lib/python3.12/dist-packages (from google-cloud-spanner<4.0.0,>=3.56.0->google-adk) (0.5.3)\n",
            "Requirement already satisfied: grpc-interceptor>=0.15.4 in /usr/local/lib/python3.12/dist-packages (from google-cloud-spanner<4.0.0,>=3.56.0->google-adk) (0.15.4)\n",
            "Requirement already satisfied: google-resumable-media<3.0.0,>=2.7.2 in /usr/local/lib/python3.12/dist-packages (from google-cloud-storage<4.0.0,>=3.0.0->google-adk) (2.7.2)\n",
            "Requirement already satisfied: httpx<1.0.0,>=0.28.1 in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.45.0->google-adk) (0.28.1)\n",
            "Requirement already satisfied: httpx-sse>=0.4 in /usr/local/lib/python3.12/dist-packages (from mcp<2.0.0,>=1.8.0->google-adk) (0.4.3)\n",
            "Requirement already satisfied: jsonschema>=4.20.0 in /usr/local/lib/python3.12/dist-packages (from mcp<2.0.0,>=1.8.0->google-adk) (4.25.1)\n",
            "Requirement already satisfied: pydantic-settings>=2.5.2 in /usr/local/lib/python3.12/dist-packages (from mcp<2.0.0,>=1.8.0->google-adk) (2.12.0)\n",
            "Requirement already satisfied: pyjwt>=2.10.1 in /usr/local/lib/python3.12/dist-packages (from pyjwt[crypto]>=2.10.1->mcp<2.0.0,>=1.8.0->google-adk) (2.10.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.9 in /usr/local/lib/python3.12/dist-packages (from mcp<2.0.0,>=1.8.0->google-adk) (0.0.20)\n",
            "Requirement already satisfied: sse-starlette>=1.6.1 in /usr/local/lib/python3.12/dist-packages (from mcp<2.0.0,>=1.8.0->google-adk) (3.0.3)\n",
            "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-api<=1.37.0,>=1.37.0->google-adk) (8.7.0)\n",
            "Requirement already satisfied: google-cloud-monitoring~=2.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-gcp-monitoring<2.0.0,>=1.9.0a0->google-adk) (2.28.0)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-http>=1.36.0->google-adk) (1.72.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.37.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-http>=1.36.0->google-adk) (1.37.0)\n",
            "Requirement already satisfied: opentelemetry-proto==1.37.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-http>=1.36.0->google-adk) (1.37.0)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.58b0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-sdk<=1.37.0,>=1.37.0->google-adk) (0.58b0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.0->google-adk) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.0->google-adk) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.0->google-adk) (0.4.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil<3.0.0,>=2.9.0.post0->google-adk) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.4->google-adk) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.4->google-adk) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.4->google-adk) (2025.10.5)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy<3.0.0,>=2.0->google-adk) (3.2.4)\n",
            "Requirement already satisfied: alembic in /usr/local/lib/python3.12/dist-packages (from sqlalchemy-spanner>=1.14.0->google-adk) (1.17.1)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.12/dist-packages (from uvicorn<1.0.0,>=0.34.0->google-adk) (0.16.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform<2.0.0,>=1.125.0->google-cloud-aiplatform[agent-engines]<2.0.0,>=1.125.0->google-adk) (1.71.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0->google-api-python-client<3.0.0,>=2.157.0->google-adk) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0->google-api-python-client<3.0.0,>=2.157.0->google-adk) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0->google-api-python-client<3.0.0,>=2.157.0->google-adk) (4.9.1)\n",
            "Requirement already satisfied: google-cloud-appengine-logging<2.0.0,>=0.1.3 in /usr/local/lib/python3.12/dist-packages (from google-cloud-logging<4->google-cloud-aiplatform[agent-engines]<2.0.0,>=1.125.0->google-adk) (1.7.0)\n",
            "Requirement already satisfied: google-cloud-audit-log<1.0.0,>=0.3.1 in /usr/local/lib/python3.12/dist-packages (from google-cloud-logging<4->google-cloud-aiplatform[agent-engines]<2.0.0,>=1.125.0->google-adk) (0.4.0)\n",
            "Requirement already satisfied: pyparsing<4,>=3.0.4 in /usr/local/lib/python3.12/dist-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client<3.0.0,>=2.157.0->google-adk) (3.2.5)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0,>=0.28.1->google-genai<2.0.0,>=1.45.0->google-adk) (1.0.9)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api<=1.37.0,>=1.37.0->google-adk) (3.23.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.20.0->mcp<2.0.0,>=1.8.0->google-adk) (25.4.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.20.0->mcp<2.0.0,>=1.8.0->google-adk) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.20.0->mcp<2.0.0,>=1.8.0->google-adk) (0.37.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.20.0->mcp<2.0.0,>=1.8.0->google-adk) (0.28.0)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.12/dist-packages (from cryptography->authlib<2.0.0,>=1.5.1->google-adk) (2.0.0)\n",
            "Requirement already satisfied: numpy>=1.21 in /usr/local/lib/python3.12/dist-packages (from shapely<3.0.0->google-cloud-aiplatform<2.0.0,>=1.125.0->google-cloud-aiplatform[agent-engines]<2.0.0,>=1.125.0->google-adk) (2.0.2)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.12/dist-packages (from alembic->sqlalchemy-spanner>=1.14.0->google-adk) (1.3.10)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.12->cryptography->authlib<2.0.0,>=1.5.1->google-adk) (2.23)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0->google-api-python-client<3.0.0,>=2.157.0->google-adk) (0.6.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.12/dist-packages (from Mako->alembic->sqlalchemy-spanner>=1.14.0->google-adk) (3.0.3)\n",
            "Downloading google_adk-1.18.0-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading google_cloud_storage-3.6.0-py3-none-any.whl (299 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m299.0/299.0 kB\u001b[0m \u001b[31m25.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tenacity-9.1.2-py3-none-any.whl (28 kB)\n",
            "Installing collected packages: tenacity, google-cloud-storage, google-adk\n",
            "  Attempting uninstall: tenacity\n",
            "    Found existing installation: tenacity 8.5.0\n",
            "    Uninstalling tenacity-8.5.0:\n",
            "      Successfully uninstalled tenacity-8.5.0\n",
            "  Attempting uninstall: google-cloud-storage\n",
            "    Found existing installation: google-cloud-storage 2.19.0\n",
            "    Uninstalling google-cloud-storage-2.19.0:\n",
            "      Successfully uninstalled google-cloud-storage-2.19.0\n",
            "  Attempting uninstall: google-adk\n",
            "    Found existing installation: google-adk 1.17.0\n",
            "    Uninstalling google-adk-1.17.0:\n",
            "      Successfully uninstalled google-adk-1.17.0\n",
            "Successfully installed google-adk-1.18.0 google-cloud-storage-3.6.0 tenacity-9.1.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google",
                  "tenacity"
                ]
              },
              "id": "eabce47c1b7c48f59562f624afdc533f"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install -U google-adk"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install google-cloud-aiplatform[adk,agent_engines] google-adk\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "N3rR2hwuCk30",
        "outputId": "70391a9d-9ebc-449a-cbf9-7fef68c7fa74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: google-adk in /usr/local/lib/python3.12/dist-packages (1.18.0)\n",
            "Requirement already satisfied: google-cloud-aiplatform[adk,agent_engines] in /usr/local/lib/python3.12/dist-packages (1.126.1)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform[adk,agent_engines]) (2.28.1)\n",
            "Requirement already satisfied: google-auth<3.0.0,>=2.14.1 in /usr/local/lib/python3.12/dist-packages (from google-cloud-aiplatform[adk,agent_engines]) (2.38.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.12/dist-packages (from google-cloud-aiplatform[adk,agent_engines]) (1.26.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in /usr/local/lib/python3.12/dist-packages (from google-cloud-aiplatform[adk,agent_engines]) (5.29.5)\n",
            "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.12/dist-packages (from google-cloud-aiplatform[adk,agent_engines]) (25.0)\n",
            "Requirement already satisfied: google-cloud-storage<4.0.0,>=1.32.0 in /usr/local/lib/python3.12/dist-packages (from google-cloud-aiplatform[adk,agent_engines]) (3.6.0)\n",
            "Requirement already satisfied: google-cloud-bigquery!=3.20.0,<4.0.0,>=1.15.0 in /usr/local/lib/python3.12/dist-packages (from google-cloud-aiplatform[adk,agent_engines]) (3.38.0)\n",
            "Requirement already satisfied: google-cloud-resource-manager<3.0.0,>=1.3.3 in /usr/local/lib/python3.12/dist-packages (from google-cloud-aiplatform[adk,agent_engines]) (1.15.0)\n",
            "Requirement already satisfied: shapely<3.0.0 in /usr/local/lib/python3.12/dist-packages (from google-cloud-aiplatform[adk,agent_engines]) (2.1.2)\n",
            "Requirement already satisfied: google-genai<2.0.0,>=1.37.0 in /usr/local/lib/python3.12/dist-packages (from google-cloud-aiplatform[adk,agent_engines]) (1.49.0)\n",
            "Requirement already satisfied: pydantic<3 in /usr/local/lib/python3.12/dist-packages (from google-cloud-aiplatform[adk,agent_engines]) (2.11.10)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.12/dist-packages (from google-cloud-aiplatform[adk,agent_engines]) (4.15.0)\n",
            "Requirement already satisfied: docstring_parser<1 in /usr/local/lib/python3.12/dist-packages (from google-cloud-aiplatform[adk,agent_engines]) (0.17.0)\n",
            "Collecting opentelemetry-instrumentation-google-genai<1.0.0,>=0.3b0 (from google-cloud-aiplatform[adk,agent_engines])\n",
            "  Downloading opentelemetry_instrumentation_google_genai-0.4b0-py3-none-any.whl.metadata (4.5 kB)\n",
            "Requirement already satisfied: cloudpickle<4.0,>=3.0 in /usr/local/lib/python3.12/dist-packages (from google-cloud-aiplatform[adk,agent_engines]) (3.1.2)\n",
            "Requirement already satisfied: google-cloud-trace<2 in /usr/local/lib/python3.12/dist-packages (from google-cloud-aiplatform[adk,agent_engines]) (1.17.0)\n",
            "Requirement already satisfied: google-cloud-logging<4 in /usr/local/lib/python3.12/dist-packages (from google-cloud-aiplatform[adk,agent_engines]) (3.12.1)\n",
            "Requirement already satisfied: opentelemetry-sdk<2 in /usr/local/lib/python3.12/dist-packages (from google-cloud-aiplatform[adk,agent_engines]) (1.37.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-gcp-logging<2 in /usr/local/lib/python3.12/dist-packages (from google-cloud-aiplatform[adk,agent_engines]) (1.11.0a0)\n",
            "Requirement already satisfied: opentelemetry-exporter-gcp-trace<2 in /usr/local/lib/python3.12/dist-packages (from google-cloud-aiplatform[adk,agent_engines]) (1.11.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-http<2 in /usr/local/lib/python3.12/dist-packages (from google-cloud-aiplatform[adk,agent_engines]) (1.37.0)\n",
            "Requirement already satisfied: PyYAML<7.0.0,>=6.0.2 in /usr/local/lib/python3.12/dist-packages (from google-adk) (6.0.3)\n",
            "Requirement already satisfied: anyio<5.0.0,>=4.9.0 in /usr/local/lib/python3.12/dist-packages (from google-adk) (4.11.0)\n",
            "Requirement already satisfied: authlib<2.0.0,>=1.5.1 in /usr/local/lib/python3.12/dist-packages (from google-adk) (1.6.5)\n",
            "Requirement already satisfied: click<9.0.0,>=8.1.8 in /usr/local/lib/python3.12/dist-packages (from google-adk) (8.3.0)\n",
            "Requirement already satisfied: fastapi<1.119.0,>=0.115.0 in /usr/local/lib/python3.12/dist-packages (from google-adk) (0.121.1)\n",
            "Requirement already satisfied: google-api-python-client<3.0.0,>=2.157.0 in /usr/local/lib/python3.12/dist-packages (from google-adk) (2.187.0)\n",
            "Requirement already satisfied: google-cloud-bigtable>=2.32.0 in /usr/local/lib/python3.12/dist-packages (from google-adk) (2.34.0)\n",
            "Requirement already satisfied: google-cloud-discoveryengine<0.14.0,>=0.13.12 in /usr/local/lib/python3.12/dist-packages (from google-adk) (0.13.12)\n",
            "Requirement already satisfied: google-cloud-secret-manager<3.0.0,>=2.22.0 in /usr/local/lib/python3.12/dist-packages (from google-adk) (2.25.0)\n",
            "Requirement already satisfied: google-cloud-spanner<4.0.0,>=3.56.0 in /usr/local/lib/python3.12/dist-packages (from google-adk) (3.59.0)\n",
            "Requirement already satisfied: google-cloud-speech<3.0.0,>=2.30.0 in /usr/local/lib/python3.12/dist-packages (from google-adk) (2.34.0)\n",
            "Requirement already satisfied: graphviz<1.0.0,>=0.20.2 in /usr/local/lib/python3.12/dist-packages (from google-adk) (0.21)\n",
            "Requirement already satisfied: mcp<2.0.0,>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from google-adk) (1.21.0)\n",
            "Requirement already satisfied: opentelemetry-api<=1.37.0,>=1.37.0 in /usr/local/lib/python3.12/dist-packages (from google-adk) (1.37.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-gcp-monitoring<2.0.0,>=1.9.0a0 in /usr/local/lib/python3.12/dist-packages (from google-adk) (1.11.0a0)\n",
            "Requirement already satisfied: opentelemetry-resourcedetector-gcp<2.0.0,>=1.9.0a0 in /usr/local/lib/python3.12/dist-packages (from google-adk) (1.11.0a0)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.9.0.post0 in /usr/local/lib/python3.12/dist-packages (from google-adk) (2.9.0.post0)\n",
            "Requirement already satisfied: python-dotenv<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from google-adk) (1.2.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.32.4 in /usr/local/lib/python3.12/dist-packages (from google-adk) (2.32.4)\n",
            "Requirement already satisfied: sqlalchemy-spanner>=1.14.0 in /usr/local/lib/python3.12/dist-packages (from google-adk) (1.17.1)\n",
            "Requirement already satisfied: sqlalchemy<3.0.0,>=2.0 in /usr/local/lib/python3.12/dist-packages (from google-adk) (2.0.44)\n",
            "Requirement already satisfied: starlette<1.0.0,>=0.46.2 in /usr/local/lib/python3.12/dist-packages (from google-adk) (0.49.3)\n",
            "Requirement already satisfied: tenacity<10.0.0,>=9.0.0 in /usr/local/lib/python3.12/dist-packages (from google-adk) (9.1.2)\n",
            "Requirement already satisfied: tzlocal<6.0,>=5.3 in /usr/local/lib/python3.12/dist-packages (from google-adk) (5.3.1)\n",
            "Requirement already satisfied: uvicorn<1.0.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from google-adk) (0.38.0)\n",
            "Requirement already satisfied: watchdog<7.0.0,>=6.0.0 in /usr/local/lib/python3.12/dist-packages (from google-adk) (6.0.0)\n",
            "Requirement already satisfied: websockets<16.0.0,>=15.0.1 in /usr/local/lib/python3.12/dist-packages (from google-adk) (15.0.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0.0,>=4.9.0->google-adk) (3.11)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0.0,>=4.9.0->google-adk) (1.3.1)\n",
            "Requirement already satisfied: cryptography in /usr/local/lib/python3.12/dist-packages (from authlib<2.0.0,>=1.5.1->google-adk) (43.0.3)\n",
            "Requirement already satisfied: annotated-doc>=0.0.2 in /usr/local/lib/python3.12/dist-packages (from fastapi<1.119.0,>=0.115.0->google-adk) (0.0.4)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform[adk,agent_engines]) (1.72.0)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform[adk,agent_engines]) (1.76.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform[adk,agent_engines]) (1.71.2)\n",
            "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client<3.0.0,>=2.157.0->google-adk) (0.31.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client<3.0.0,>=2.157.0->google-adk) (0.2.1)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client<3.0.0,>=2.157.0->google-adk) (4.2.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.14.1->google-cloud-aiplatform[adk,agent_engines]) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.14.1->google-cloud-aiplatform[adk,agent_engines]) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.14.1->google-cloud-aiplatform[adk,agent_engines]) (4.9.1)\n",
            "Requirement already satisfied: google-cloud-core<3.0.0,>=2.4.1 in /usr/local/lib/python3.12/dist-packages (from google-cloud-bigquery!=3.20.0,<4.0.0,>=1.15.0->google-cloud-aiplatform[adk,agent_engines]) (2.5.0)\n",
            "Requirement already satisfied: google-resumable-media<3.0.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-cloud-bigquery!=3.20.0,<4.0.0,>=1.15.0->google-cloud-aiplatform[adk,agent_engines]) (2.7.2)\n",
            "Requirement already satisfied: grpc-google-iam-v1<1.0.0,>=0.12.4 in /usr/local/lib/python3.12/dist-packages (from google-cloud-bigtable>=2.32.0->google-adk) (0.14.3)\n",
            "Requirement already satisfied: google-crc32c<2.0.0dev,>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from google-cloud-bigtable>=2.32.0->google-adk) (1.7.1)\n",
            "Requirement already satisfied: google-cloud-appengine-logging<2.0.0,>=0.1.3 in /usr/local/lib/python3.12/dist-packages (from google-cloud-logging<4->google-cloud-aiplatform[adk,agent_engines]) (1.7.0)\n",
            "Requirement already satisfied: google-cloud-audit-log<1.0.0,>=0.3.1 in /usr/local/lib/python3.12/dist-packages (from google-cloud-logging<4->google-cloud-aiplatform[adk,agent_engines]) (0.4.0)\n",
            "Requirement already satisfied: sqlparse>=0.4.4 in /usr/local/lib/python3.12/dist-packages (from google-cloud-spanner<4.0.0,>=3.56.0->google-adk) (0.5.3)\n",
            "Requirement already satisfied: grpc-interceptor>=0.15.4 in /usr/local/lib/python3.12/dist-packages (from google-cloud-spanner<4.0.0,>=3.56.0->google-adk) (0.15.4)\n",
            "Requirement already satisfied: httpx<1.0.0,>=0.28.1 in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.37.0->google-cloud-aiplatform[adk,agent_engines]) (0.28.1)\n",
            "Requirement already satisfied: httpx-sse>=0.4 in /usr/local/lib/python3.12/dist-packages (from mcp<2.0.0,>=1.8.0->google-adk) (0.4.3)\n",
            "Requirement already satisfied: jsonschema>=4.20.0 in /usr/local/lib/python3.12/dist-packages (from mcp<2.0.0,>=1.8.0->google-adk) (4.25.1)\n",
            "Requirement already satisfied: pydantic-settings>=2.5.2 in /usr/local/lib/python3.12/dist-packages (from mcp<2.0.0,>=1.8.0->google-adk) (2.12.0)\n",
            "Requirement already satisfied: pyjwt>=2.10.1 in /usr/local/lib/python3.12/dist-packages (from pyjwt[crypto]>=2.10.1->mcp<2.0.0,>=1.8.0->google-adk) (2.10.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.9 in /usr/local/lib/python3.12/dist-packages (from mcp<2.0.0,>=1.8.0->google-adk) (0.0.20)\n",
            "Requirement already satisfied: sse-starlette>=1.6.1 in /usr/local/lib/python3.12/dist-packages (from mcp<2.0.0,>=1.8.0->google-adk) (3.0.3)\n",
            "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-api<=1.37.0,>=1.37.0->google-adk) (8.7.0)\n",
            "Requirement already satisfied: google-cloud-monitoring~=2.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-gcp-monitoring<2.0.0,>=1.9.0a0->google-adk) (2.28.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.37.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-http<2->google-cloud-aiplatform[adk,agent_engines]) (1.37.0)\n",
            "Requirement already satisfied: opentelemetry-proto==1.37.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-http<2->google-cloud-aiplatform[adk,agent_engines]) (1.37.0)\n",
            "Collecting opentelemetry-instrumentation<2,>=0.58b0 (from opentelemetry-instrumentation-google-genai<1.0.0,>=0.3b0->google-cloud-aiplatform[adk,agent_engines])\n",
            "  Downloading opentelemetry_instrumentation-0.59b0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions<2,>=0.58b0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-instrumentation-google-genai<1.0.0,>=0.3b0->google-cloud-aiplatform[adk,agent_engines]) (0.58b0)\n",
            "Collecting opentelemetry-util-genai<0.3b0,>=0.2b0 (from opentelemetry-instrumentation-google-genai<1.0.0,>=0.3b0->google-cloud-aiplatform[adk,agent_engines])\n",
            "  Downloading opentelemetry_util_genai-0.2b0-py3-none-any.whl.metadata (3.2 kB)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->google-cloud-aiplatform[adk,agent_engines]) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->google-cloud-aiplatform[adk,agent_engines]) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->google-cloud-aiplatform[adk,agent_engines]) (0.4.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil<3.0.0,>=2.9.0.post0->google-adk) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.4->google-adk) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.4->google-adk) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.4->google-adk) (2025.10.5)\n",
            "Requirement already satisfied: numpy>=1.21 in /usr/local/lib/python3.12/dist-packages (from shapely<3.0.0->google-cloud-aiplatform[adk,agent_engines]) (2.0.2)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy<3.0.0,>=2.0->google-adk) (3.2.4)\n",
            "Requirement already satisfied: alembic in /usr/local/lib/python3.12/dist-packages (from sqlalchemy-spanner>=1.14.0->google-adk) (1.17.1)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.12/dist-packages (from uvicorn<1.0.0,>=0.34.0->google-adk) (0.16.0)\n",
            "Requirement already satisfied: pyparsing<4,>=3.0.4 in /usr/local/lib/python3.12/dist-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client<3.0.0,>=2.157.0->google-adk) (3.2.5)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0,>=0.28.1->google-genai<2.0.0,>=1.37.0->google-cloud-aiplatform[adk,agent_engines]) (1.0.9)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api<=1.37.0,>=1.37.0->google-adk) (3.23.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.20.0->mcp<2.0.0,>=1.8.0->google-adk) (25.4.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.20.0->mcp<2.0.0,>=1.8.0->google-adk) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.20.0->mcp<2.0.0,>=1.8.0->google-adk) (0.37.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.20.0->mcp<2.0.0,>=1.8.0->google-adk) (0.28.0)\n",
            "INFO: pip is looking at multiple versions of opentelemetry-instrumentation to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting opentelemetry-instrumentation<2,>=0.58b0 (from opentelemetry-instrumentation-google-genai<1.0.0,>=0.3b0->google-cloud-aiplatform[adk,agent_engines])\n",
            "  Downloading opentelemetry_instrumentation-0.58b0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting wrapt<2.0.0,>=1.0.0 (from opentelemetry-instrumentation<2,>=0.58b0->opentelemetry-instrumentation-google-genai<1.0.0,>=0.3b0->google-cloud-aiplatform[adk,agent_engines])\n",
            "  Downloading wrapt-1.17.3-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (6.4 kB)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0,>=2.14.1->google-cloud-aiplatform[adk,agent_engines]) (0.6.1)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.12/dist-packages (from cryptography->authlib<2.0.0,>=1.5.1->google-adk) (2.0.0)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.12/dist-packages (from alembic->sqlalchemy-spanner>=1.14.0->google-adk) (1.3.10)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.12->cryptography->authlib<2.0.0,>=1.5.1->google-adk) (2.23)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.12/dist-packages (from Mako->alembic->sqlalchemy-spanner>=1.14.0->google-adk) (3.0.3)\n",
            "Downloading opentelemetry_instrumentation_google_genai-0.4b0-py3-none-any.whl (29 kB)\n",
            "Downloading opentelemetry_instrumentation-0.58b0-py3-none-any.whl (33 kB)\n",
            "Downloading opentelemetry_util_genai-0.2b0-py3-none-any.whl (22 kB)\n",
            "Downloading wrapt-1.17.3-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (88 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m88.0/88.0 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: wrapt, opentelemetry-instrumentation, opentelemetry-util-genai, opentelemetry-instrumentation-google-genai\n",
            "  Attempting uninstall: wrapt\n",
            "    Found existing installation: wrapt 2.0.1\n",
            "    Uninstalling wrapt-2.0.1:\n",
            "      Successfully uninstalled wrapt-2.0.1\n",
            "Successfully installed opentelemetry-instrumentation-0.58b0 opentelemetry-instrumentation-google-genai-0.4b0 opentelemetry-util-genai-0.2b0 wrapt-1.17.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üì¶ Importing Required Libraries\n",
        "Here we load all the Python libraries used throughout the project.This includes Vertex AI, ADK components, PDF readers, and utility modules.  \n"
      ],
      "metadata": {
        "id": "nGvizC0mj5Vo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import time\n",
        "import vertexai\n",
        "from vertexai import agent_engines\n",
        "\n",
        "print(\"‚úÖ Imports completed successfully\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wCSL92zEA3I9",
        "outputId": "9ea7880c-48f8-48c0-a3c9-ed724aee0644"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Imports completed successfully\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üîê Configuring API Keys and Project Settings\n",
        "In this section, we connect our notebook to the correct Google Cloud project.  \n",
        "We set environment variables for:\n",
        "- Project ID  \n",
        "- API keys  \n",
        "- Region  \n",
        "These values tell Vertex AI and ADK where to deploy and run our agent.\n"
      ],
      "metadata": {
        "id": "uZTOjvOfkHx4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "import os\n",
        "GOOGLE_API_KEY = userdata.get('GOOGLE_API_KEY')\n",
        "os.environ['GOOGLE_API_KEY'] = GOOGLE_API_KEY"
      ],
      "metadata": {
        "id": "6H-wQ0GHA5wx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Set your PROJECT_ID\n",
        "PROJECT_ID = \"my-research-agent-478404\"  # TODO: Replace with your project ID\n",
        "os.environ[\"GOOGLE_CLOUD_PROJECT\"] = PROJECT_ID\n",
        "\n",
        "if PROJECT_ID == \"your-project-id\" or not PROJECT_ID:\n",
        "    raise ValueError(\"‚ö†Ô∏è Please replace 'your-project-id' with your actual Google Cloud Project ID.\")\n",
        "\n",
        "print(f\"‚úÖ Project ID set to: {PROJECT_ID}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LfsjY21EA-3u",
        "outputId": "89bb2719-b959-4894-e00e-626e0aa21cc9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Project ID set to: my-research-agent-478404\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üìÅ Preparing Project Structure\n",
        "We create a dedicated folder (`research_agent/`) to store all files for the\n",
        "research agent ‚Äî such as Python scripts, requirements, environment configs, and\n",
        "agent engine files.  \n",
        "\n"
      ],
      "metadata": {
        "id": "R5HekkJmkPdS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p research_agent\n"
      ],
      "metadata": {
        "id": "IBnlH7dGBtYi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile research_agent/requirements.txt\n",
        "google-adk\n",
        "google-cloud-aiplatform[adk,agent_engines]>=1.111\n",
        "opentelemetry-instrumentation-google-genai\n",
        "pypdf\n",
        "requests\n",
        "google-genai\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZbLGHJdkB-UU",
        "outputId": "980af237-f10a-47ea-f1f9-da0579dd7563"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing research_agent/requirements.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile research_agent/.env\n",
        "\n",
        "# https://cloud.google.com/vertex-ai/generative-ai/docs/learn/locations#global-endpoint\n",
        "GOOGLE_CLOUD_PROJECT=\"my-research-agent-478404\"\n",
        "GOOGLE_CLOUD_LOCATION=\"us-east4\"\n",
        "GOOGLE_GENAI_USE_VERTEXAI=1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fKh7wCwZCEAn",
        "outputId": "c90a519f-facd-4039-806b-c4f2fcc4fdbc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing research_agent/.env\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile research_agent/.agent_engine_config.json\n",
        "{\n",
        "  \"min_instances\": 0,\n",
        "  \"max_instances\": 1,\n",
        "  \"resource_limits\": {\n",
        "    \"cpu\": \"1\",\n",
        "    \"memory\": \"2Gi\"\n",
        "  }\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wkOV-8-RCNGZ",
        "outputId": "cc04746a-d80a-4211-d17b-36c64f5cf6ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing research_agent/.agent_engine_config.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import vertexai\n",
        "import os\n",
        "\n",
        "PROJECT_ID = \"my-research-agent-478404\"\n",
        "REGION = \"us-east4\"\n",
        "BUCKET = \"gs://my-research-agent-staging\"\n",
        "\n",
        "# MUST BE SET BEFORE vertexai.init()\n",
        "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"/content/my-research-agent-478404-594c8dc978b0.json\"\n",
        "\n",
        "vertexai.init(\n",
        "    project=PROJECT_ID,\n",
        "    location=REGION,\n",
        "    staging_bucket=BUCKET,\n",
        ")\n",
        "\n",
        "print(\"Vertex AI initialized with service account JSON\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "abTsAdfcDRI2",
        "outputId": "10c01bd8-9978-43d9-98da-234589ec46fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vertex AI initialized with service account JSON\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"/content/my-research-agent-478404-594c8dc978b0.json\"\n",
        "\n",
        "print(\"Credentials set.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k5Jy32I_DYQT",
        "outputId": "e0f27f4e-56de-4119-ad4f-773a5a2873f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Credentials set.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ü§ñ Building the Research Agent\n",
        "In this section, we define the entire agent pipeline:\n",
        "- PDF reader tool  \n",
        "- Document reader agent  \n",
        "- Context builder agent  \n",
        "- Summarizer agent  \n",
        "- Evaluator agent  \n",
        "- Root orchestrator agent  \n",
        "This is the heart of the project ‚Äî it automates the full research-paper workflow.\n"
      ],
      "metadata": {
        "id": "AqLsu3T9kdLp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile research_agent/agent.py\n",
        "import os\n",
        "import tempfile\n",
        "\n",
        "import vertexai\n",
        "from google.genai import types\n",
        "\n",
        "from google.adk.agents import Agent, LlmAgent\n",
        "from google.adk.tools import AgentTool\n",
        "from google.adk.models.google_llm import Gemini\n",
        "\n",
        "from pypdf import PdfReader\n",
        "from google.cloud import storage\n",
        "\n",
        "# -------------------------------------------------------------------\n",
        "# Vertex AI init\n",
        "# -------------------------------------------------------------------\n",
        "PROJECT_ID = os.environ[\"GOOGLE_CLOUD_PROJECT\"]\n",
        "LOCATION = os.environ[\"GOOGLE_CLOUD_LOCATION\"]\n",
        "BUCKET = \"gs://my-research-agent-staging\"\n",
        "\n",
        "vertexai.init(\n",
        "    project=PROJECT_ID,\n",
        "    location=LOCATION,\n",
        "    staging_bucket=BUCKET,\n",
        ")\n",
        "\n",
        "# -------------------------------------------------------------------\n",
        "# PDF Reader ‚Äì plain Python tool function (NO AgentTool subclass)\n",
        "# -------------------------------------------------------------------\n",
        "def pdf_reader_tool(file_path: str) -> dict:\n",
        "    \"\"\"\n",
        "    Reads a PDF either from local path or GCS (gs://bucket/path.pdf)\n",
        "    and returns the extracted text.\n",
        "\n",
        "    Args:\n",
        "        file_path: Local path or GCS URI to the PDF.\n",
        "\n",
        "    Returns:\n",
        "        dict: {\"status\": \"success\", \"text\": \"<full extracted text>\"} or\n",
        "              {\"status\": \"error\", \"error\": \"<message>\"} on failure.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Create a temporary local file to store the PDF\n",
        "        temp_pdf = tempfile.NamedTemporaryFile(\n",
        "            delete=False, suffix=\".pdf\"\n",
        "        ).name\n",
        "\n",
        "        # If path is GCS, download first\n",
        "        if file_path.startswith(\"gs://\"):\n",
        "            storage_client = storage.Client()\n",
        "            path_no_scheme = file_path.replace(\"gs://\", \"\", 1)\n",
        "            bucket_name = path_no_scheme.split(\"/\")[0]\n",
        "            blob_name = \"/\".join(path_no_scheme.split(\"/\")[1:])\n",
        "\n",
        "            bucket = storage_client.bucket(bucket_name)\n",
        "            blob = bucket.blob(blob_name)\n",
        "            blob.download_to_filename(temp_pdf)\n",
        "            local_path = temp_pdf\n",
        "        else:\n",
        "            # Treat as local file path\n",
        "            local_path = file_path\n",
        "\n",
        "        # Extract text from PDF\n",
        "        reader = PdfReader(local_path)\n",
        "        text = \"\\n\".join(page.extract_text() or \"\" for page in reader.pages)\n",
        "\n",
        "        return {\"status\": \"success\", \"text\": text}\n",
        "\n",
        "    except Exception as e:\n",
        "        return {\"status\": \"error\", \"error\": str(e)}\n",
        "\n",
        "\n",
        "# -------------------------------------------------------------------\n",
        "# Retry config for all LLM agents\n",
        "# -------------------------------------------------------------------\n",
        "retry = types.HttpRetryOptions(\n",
        "    attempts=5,\n",
        "    exp_base=2,\n",
        "    initial_delay=1,\n",
        "    http_status_codes=[429, 500, 503, 504],\n",
        ")\n",
        "\n",
        "# -------------------------------------------------------------------\n",
        "# Agent 1 ‚Äì Document Reader\n",
        "# -------------------------------------------------------------------\n",
        "document_reader = LlmAgent(\n",
        "    name=\"document_reader\",\n",
        "    model=Gemini(model=\"gemini-2.0-flash\", retry_options=retry),\n",
        "    instruction=\"\"\"\n",
        "You receive the FULL TEXT of a research paper.\n",
        "\n",
        "Your job is to transform it into CLEAN, STRUCTURED MARKDOWN:\n",
        "\n",
        "- Title\n",
        "- Authors (if available)\n",
        "- Abstract\n",
        "- Sections with headings\n",
        "- Important equations (LaTeX if possible)\n",
        "- Tables (in text form)\n",
        "\n",
        "RULES:\n",
        "- Do NOT summarize.\n",
        "- Do NOT add your own commentary.\n",
        "- Just restructure and clean the content.\n",
        "\"\"\",\n",
        ")\n",
        "\n",
        "# -------------------------------------------------------------------\n",
        "# Agent 2 ‚Äì Context Builder\n",
        "# -------------------------------------------------------------------\n",
        "context_builder = LlmAgent(\n",
        "    name=\"context_builder\",\n",
        "    model=Gemini(model=\"gemini-2.0-flash\", retry_options=retry),\n",
        "    instruction=\"\"\"\n",
        "You receive structured markdown for a research paper.\n",
        "\n",
        "Compress it into 400‚Äì600 words while preserving:\n",
        "- Motivation / problem\n",
        "- Methods / approach\n",
        "- Datasets / inputs\n",
        "- Results\n",
        "- Conclusions\n",
        "\n",
        "RULES:\n",
        "- Do NOT invent details.\n",
        "- Keep wording clear and dense.\n",
        "\"\"\",\n",
        ")\n",
        "\n",
        "# -------------------------------------------------------------------\n",
        "# Agent 3 ‚Äì Summarizer\n",
        "# -------------------------------------------------------------------\n",
        "summarizer = LlmAgent(\n",
        "    name=\"summarizer\",\n",
        "    model=Gemini(model=\"gemini-2.0-flash\", retry_options=retry),\n",
        "    instruction=\"\"\"\n",
        "You receive a compressed 400‚Äì600 word context about a research paper.\n",
        "\n",
        "Produce a STUDENT-FRIENDLY summary with these sections:\n",
        "\n",
        "1. Title\n",
        "2. Problem\n",
        "3. Background / Motivation\n",
        "4. Method / Model\n",
        "5. Dataset / Inputs\n",
        "6. Results (include important numbers if present)\n",
        "7. Strengths\n",
        "8. Limitations\n",
        "9. Key Takeaways (5‚Äì10 bullet points)\n",
        "10. Overall Conclusion\n",
        "\n",
        "RULES:\n",
        "- Length: about 300‚Äì600 words.\n",
        "- Use simple, clear English suitable for a CS/AI student.\n",
        "\"\"\",\n",
        ")\n",
        "\n",
        "# -------------------------------------------------------------------\n",
        "# Agent 4 ‚Äì Evaluator\n",
        "# -------------------------------------------------------------------\n",
        "evaluator = LlmAgent(\n",
        "    name=\"evaluator\",\n",
        "    model=Gemini(model=\"gemini-2.0-flash\", retry_options=retry),\n",
        "    instruction=\"\"\"\n",
        "You receive:\n",
        "- The compressed context of a research paper.\n",
        "- A candidate summary written for students.\n",
        "\n",
        "Evaluate ONLY on:\n",
        "- Technical correctness\n",
        "- Clarity\n",
        "- Completeness (are key ideas covered?)\n",
        "\n",
        "Output:\n",
        "- SHORT bullet-point feedback listing issues or confirming quality.\n",
        "\n",
        "Do NOT rewrite the summary.\n",
        "\"\"\",\n",
        ")\n",
        "\n",
        "# -------------------------------------------------------------------\n",
        "# Wrap the LLM agents as AgentTools\n",
        "# -------------------------------------------------------------------\n",
        "document_reader_tool = AgentTool(agent=document_reader)\n",
        "context_builder_tool = AgentTool(agent=context_builder)\n",
        "summarizer_tool = AgentTool(agent=summarizer)\n",
        "evaluator_tool = AgentTool(agent=evaluator)\n",
        "\n",
        "# -------------------------------------------------------------------\n",
        "# ROOT AGENT ‚Äì Orchestrator\n",
        "# -------------------------------------------------------------------\n",
        "root_agent = Agent(\n",
        "    name=\"research_analyst\",\n",
        "    model=\"gemini-2.0-flash\",\n",
        "    description=(\n",
        "        \"Reads research PDFs (from GCS or local path), extracts text, and \"\n",
        "        \"produces detailed, student-friendly summaries.\"\n",
        "    ),\n",
        "    instruction=\"\"\"\n",
        "You are the RESEARCH ANALYST AGENT.\n",
        "\n",
        "Your pipeline MUST follow these steps in order:\n",
        "\n",
        "1Ô∏è‚É£ Call `pdf_reader_tool(file_path=...)`\n",
        "    - Input is a GCS URI (gs://...) or local path to a PDF.\n",
        "    - If the tool returns status != \"success\", explain the error.\n",
        "\n",
        "2Ô∏è‚É£ Call `document_reader` on the extracted text to produce CLEAN MARKDOWN.\n",
        "\n",
        "3Ô∏è‚É£ Call `context_builder` on that markdown to get a 400‚Äì600 word context.\n",
        "\n",
        "4Ô∏è‚É£ Call `summarizer` on the context to produce a student-friendly summary.\n",
        "\n",
        "5Ô∏è‚É£ Call `evaluator` with BOTH the context and the summary.\n",
        "    - Use the evaluator's feedback to fix any obvious mistakes.\n",
        "\n",
        "6Ô∏è‚É£ Return ONLY the final improved summary to the user.\n",
        "    - Do NOT include raw PDF text.\n",
        "    - Do NOT include intermediate tool outputs.\n",
        "    - Do NOT include evaluator comments in the final answer.\n",
        "\n",
        "FINAL SUMMARY RULES:\n",
        "- 300‚Äì600 words.\n",
        "- Clear, organized, and easy to understand for a CS/AI student.\n",
        "\"\"\",\n",
        "    tools=[\n",
        "        pdf_reader_tool,          # plain Python function tool\n",
        "        document_reader_tool,     # LLM tools\n",
        "        context_builder_tool,\n",
        "        summarizer_tool,\n",
        "        evaluator_tool,\n",
        "    ],\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ydudompXCP56",
        "outputId": "d7f20ef5-0a6b-4ef4-b9b9-f092ba6bf228"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing research_agent/agent.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üöÄ Deploying Agent Engine to Vertex AI\n",
        "We package all files, build the agent engine, and deploy it to Google Cloud.  \n",
        "Once deployed, the agent becomes available as a cloud service you can query\n",
        "remotely.\n"
      ],
      "metadata": {
        "id": "tF-5rkp4ki4W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!adk deploy agent_engine \\\n",
        " --project=$PROJECT_ID \\\n",
        " --region=us-east4 \\\n",
        " research_agent \\\n",
        " --agent_engine_config_file=research_agent/.agent_engine_config.json\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2eVBH8CFCXCD",
        "outputId": "6c05d489-4c72-448c-db5f-3a6ca2cbb916"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Staging all files in: /content/research_agent_tmp20251118_041236\n",
            "Copying agent source code...\n",
            "Copying agent source code complete.\n",
            "Resolving files and dependencies...\n",
            "Reading agent engine config from research_agent/.agent_engine_config.json\n",
            "Reading environment variables from /content/research_agent/.env\n",
            "\u001b[33mIgnoring GOOGLE_CLOUD_PROJECT in .env as `--project` was explicitly passed and takes precedence\u001b[0m\n",
            "\u001b[33mIgnoring GOOGLE_CLOUD_LOCATION in .env as `--region` was explicitly passed and takes precedence\u001b[0m\n",
            "Initializing Vertex AI...\n",
            "Vertex AI initialized.\n",
            "Created research_agent_tmp20251118_041236/agent_engine_app.py\n",
            "Files and dependencies resolved\n",
            "Deploying to agent engine...\n",
            "\u001b[32m‚úÖ Created agent engine: projects/610233153602/locations/us-east4/reasoningEngines/7301707186479038464\u001b[0m\n",
            "Cleaning up the temp folder: research_agent_tmp20251118_041236\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üîó Connecting to Deployed Agent\n",
        "After deployment, we fetch the agent from Vertex AI.  \n",
        "This allows us to send queries, upload PDFs, and run the agent pipeline in the cloud.\n"
      ],
      "metadata": {
        "id": "_2MbTgZZkoyR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "deployed_region = \"us-east4\"\n",
        "# Initialize Vertex AI\n",
        "vertexai.init(project=PROJECT_ID, location=deployed_region)\n",
        "\n",
        "# Get the most recently deployed agent\n",
        "agents_list = list(agent_engines.list())\n",
        "if agents_list:\n",
        "    remote_agent = agents_list[0]  # Get the first (most recent) agent\n",
        "    client = agent_engines\n",
        "    print(f\"‚úÖ Connected to deployed agent: {remote_agent.resource_name}\")\n",
        "else:\n",
        "    print(\"‚ùå No agents found. Please deploy first.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jte9yWn0Dx1l",
        "outputId": "37f9b064-03d3-44f6-f211-fd541acf1eff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Connected to deployed agent: projects/610233153602/locations/us-east4/reasoningEngines/7301707186479038464\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üì§ Uploading PDF to Google Cloud Storage\n",
        "We upload a PDF document to our GCS bucket.  \n",
        "The agent will read this file directly during processing.\n"
      ],
      "metadata": {
        "id": "40JzBakuksQn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.genai import types\n",
        "\n",
        "pdf_part = types.Part.from_uri(\n",
        "    file_uri=\"gs://my-research-agent-staging/uploads/ase10.pdf\",\n",
        "    mime_type=\"application/pdf\",\n",
        ")\n",
        "\n",
        "async for event in remote_agent.async_stream_query(\n",
        "    user_id=\"u1\",\n",
        "    message=\"Process this PDF and return final research summary.\",\n",
        "    attachments=[pdf_part],\n",
        "):\n",
        "    print(event)\n"
      ],
      "metadata": {
        "id": "E1DxZAawgX_B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!gcloud auth activate-service-account --key-file=\"/content/my-research-agent-478404-594c8dc978b0.json\"\n",
        "!gcloud config set project my-research-agent-478404\n"
      ],
      "metadata": {
        "id": "q2Tf_IhkGlwp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!gsutil cp \"/content/ase_10.pdf\" gs://my-research-agent-staging/uploads/ase10.pdf\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kux3kWm5GPZB",
        "outputId": "bf54848a-fe6d-4777-abed-12d68d1b080a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Copying file:///content/ase_10.pdf [Content-Type=application/pdf]...\n",
            "/ [0 files][    0.0 B/535.5 KiB]                                                \r/ [1 files][535.5 KiB/535.5 KiB]                                                \r\n",
            "Operation completed over 1 objects/535.5 KiB.                                    \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Sample Test"
      ],
      "metadata": {
        "id": "S9EOhkwHkvOV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "async for event in remote_agent.async_stream_query(\n",
        "    user_id=\"u1\",\n",
        "    message=\"Hello, what can you do?\"\n",
        "):\n",
        "    print(event)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dl-uZA8vGP6D",
        "outputId": "262c3bbe-5d57-44a0-cb9e-1da0fe3019f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'model_version': 'gemini-2.0-flash', 'content': {'parts': [{'text': 'I can read research PDFs, extract the text, create a context, summarize the content in a student-friendly manner, and evaluate the summary for improvements. What PDF would you like me to process? Please provide the file path.\\n'}], 'role': 'model'}, 'finish_reason': 'STOP', 'usage_metadata': {'candidates_token_count': 47, 'candidates_tokens_details': [{'modality': 'TEXT', 'token_count': 47}], 'prompt_token_count': 434, 'prompt_tokens_details': [{'modality': 'TEXT', 'token_count': 434}], 'total_token_count': 481, 'traffic_type': 'ON_DEMAND'}, 'avg_logprobs': -0.09033814896928503, 'invocation_id': 'e-3df69f02-7b51-4987-9999-67b14bde1b68', 'author': 'research_analyst', 'actions': {'state_delta': {}, 'artifact_delta': {}, 'requested_auth_configs': {}, 'requested_tool_confirmations': {}}, 'id': '147950fd-b574-4eb1-a311-797fde81a553', 'timestamp': 1763439567.787122}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üß† Running the Research Agent End-to-End\n",
        "Finally, we send a query to the deployed agent along with the PDF.  \n",
        "The agent:\n",
        "1. Reads the PDF  \n",
        "2. Cleans the text  \n",
        "3. Builds a context  \n",
        "4. Summarizes  \n",
        "5. Evaluates & improves  \n",
        "6. Returns the final summary  \n",
        "\n",
        "This is where everything comes together and you see the full pipeline in action.\n"
      ],
      "metadata": {
        "id": "pWQAbt9rkzjT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "async for event in remote_agent.async_stream_query(\n",
        "    user_id=\"u1\",\n",
        "    message=(\n",
        "        \"Process this PDF and give me the final summary. \"\n",
        "        \"file_path=gs://my-research-agent-staging/uploads/ase10.pdf\"\n",
        "    ),\n",
        "):\n",
        "    print(event)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "feliMFE2awpn",
        "outputId": "d1967153-ab7a-44be-b7d5-1f44bea16b30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'model_version': 'gemini-2.0-flash', 'content': {'parts': [{'text': \"Okay, I will process the PDF from the given GCS path and provide you with a student-friendly summary. Here's the plan:\\n\\n1.  **Read the PDF:** Use `pdf_reader_tool` to extract text from the PDF.\\n2.  **Clean the text:** Use `document_reader` to clean the extracted text and convert it to markdown.\\n3.  **Build context:** Use `context_builder` to create a detailed context from the markdown.\\n4.  **Summarize:** Use `summarizer` to generate an initial summary of the context.\\n5.  **Evaluate:** Use `evaluator` to evaluate the summary and context.\\n6.  **Improve:** Based on the evaluation, refine the summary.\\n7.  **Return:** Provide you with the final, improved summary.\\n\\nLet's start by reading the PDF.\\n\\n\"}, {'function_call': {'id': 'adk-eba62ace-23ad-4d90-8476-f20bda6cdbbf', 'args': {'file_path': 'gs://my-research-agent-staging/uploads/ase10.pdf'}, 'name': 'pdf_reader_tool'}}], 'role': 'model'}, 'finish_reason': 'STOP', 'usage_metadata': {'candidates_token_count': 210, 'candidates_tokens_details': [{'modality': 'TEXT', 'token_count': 210}], 'prompt_token_count': 458, 'prompt_tokens_details': [{'modality': 'TEXT', 'token_count': 458}], 'total_token_count': 668, 'traffic_type': 'ON_DEMAND'}, 'avg_logprobs': -0.0712710698445638, 'invocation_id': 'e-6c079805-1a85-40d7-83b0-829f404e126f', 'author': 'research_analyst', 'actions': {'state_delta': {}, 'artifact_delta': {}, 'requested_auth_configs': {}, 'requested_tool_confirmations': {}}, 'long_running_tool_ids': [], 'id': 'c67c4460-8018-4c39-bcdd-49d753e2660a', 'timestamp': 1763439382.36167}\n",
            "{'content': {'parts': [{'function_response': {'id': 'adk-eba62ace-23ad-4d90-8476-f20bda6cdbbf', 'name': 'pdf_reader_tool', 'response': {'status': 'success', 'text': '1\\nLarge Language Models for Information\\nRetrieval: A Survey\\nYutao Zhu, Huaying Yuan, Shuting Wang, Jiongnan Liu, Wenhan Liu, Chenlong Deng\\nHaonan Chen, Zheng Liu, Zhicheng Dou, and Ji-Rong Wen\\nAbstract‚ÄîAs a primary means of information acquisition, information retrieval (IR) systems, such as search engines, have integrated\\nthemselves into our daily lives. These systems also serve as components of dialogue, question-answering, and recommender systems.\\nThe trajectory of IR has evolved dynamically from its origins in term-based methods to its integration with advanced neural models.\\nWhile the neural models excel at capturing complex contextual signals and semantic nuances, thereby reshaping the IR landscape,\\nthey still face challenges such as data scarcity, interpretability, and the generation of contextually plausible yet potentially inaccurate\\nresponses. This evolution requires a combination of both traditional methods (such as term-based sparse retrieval methods with rapid\\nresponse) and modern neural architectures (such as language models with powerful language understanding capacity). Meanwhile,\\nthe emergence of large language models (LLMs), typified by ChatGPT and GPT -4, has revolutionized natural language processing due\\nto their remarkable language understanding, generation, generalization, and reasoning abilities. Consequently, recent research has\\nsought to leverage LLMs to improve IR systems. Given the rapid evolution of this research trajectory, it is necessary to consolidate\\nexisting methodologies and provide nuanced insights through a comprehensive overview. In this survey, we delve into the confluence\\nof LLMs and IR systems, including crucial aspects such as query rewriters, retrievers, rerankers, and readers. Additionally, we explore\\npromising directions, such as search agents, within this expanding field.\\nIndex Terms‚ÄîLarge Language Models; Information Retrieval; Query Rewriter; Reranking; Reader; Fine-tuning; Prompting\\n‚ú¶\\n1 I NTRODUCTION\\nI\\nNFORMATION access is one of the fundamental daily\\nneeds of human beings. To fulfill the need for rapid\\nacquisition of desired information, various information re-\\ntrieval (IR) systems have been developed [1‚Äì4]. Prominent\\nexamples include search engines such as Google, Bing, and\\nBaidu, which serve as IR systems on the Internet, adept at\\nretrieving relevant web pages in response to user queries,\\nand provide convenient and efficient access to information\\non the Internet. It is worth noting that IR extends beyond\\nweb page retrieval. In dialogue systems (chatbots) [1, 5‚Äì\\n8], such as Microsoft Xiaoice [2], Apple Siri, 1 and Google\\nAssistant,2 IR systems play a crucial role in retrieving appro-\\npriate responses to user input utterances, thereby producing\\nnatural and fluent human-machine conversations. Similarly,\\nin question-answering systems [3, 9], IR systems are em-\\nployed to select relevant clues essential for addressing user\\nquestions effectively. In image search engines [4], IR systems\\nexcel at returning images that align with user input queries.\\nGiven the exponential growth of information, research and\\nindustry have become increasingly interested in the devel-\\nopment of effective IR systems.\\nThe core function of an IR system is retrieval, which aims\\nto determine the relevance between a user-issued query\\nand the content to be retrieved, including various types\\nof information such as texts, images, music, and more. For\\nAll authors except Zheng Liu are from Gaoling School of Artificial Intelligence\\nand School of Information, Renmin University of China. Zheng Liu is from\\nBeijing Academy of Artificial Intelligence, China.\\nContact e-mail: yutaozhu94@gmail.com, dou@ruc.edu.cn\\n1. Apple Siri, https://www.apple.com/siri/\\n2. Google Assistant, https://assistant.google.com/\\nthe scope of this survey, we concentrate solely on review-\\ning those text retrieval systems, in which query-document\\nrelevance is commonly measured by their matching score. 3\\nGiven that IR systems operate on extensive repositories,\\nthe efficiency of retrieval algorithms becomes of paramount\\nimportance. To improve the user experience, the retrieval\\nperformance is enhanced from both the upstream (query\\nreformulation) and downstream (reranking and reading)\\nperspectives. As an upstream technique, query reformu-\\nlation is designed to refine user queries so that they are\\nmore effective at retrieving relevant documents [10, 11].\\nWith the recent surge in the popularity of conversational\\nsearch, this technique has received increasing attention. On\\nthe downstream side, reranking approaches are developed\\nto further adjust the document ranking [12‚Äì14]. In contrast\\nto the retrieval stage, reranking is performed only on a\\nlimited set of relevant documents, already retrieved by the\\nretriever. Under this circumstance, the emphasis is placed\\non achieving higher performance rather than keeping higher\\nefficiency, allowing for the application of more complex ap-\\nproaches in the reranking process. Additionally, reranking\\ncan accommodate other specific requirements, such as per-\\nsonalization [15‚Äì18] and diversification [19‚Äì22]. Following\\nthe retrieval and reranking stages, a reading component is\\nincorporated to summarize the retrieved documents and de-\\nliver a concise document to users [23, 24]. While traditional\\nIR systems typically require users to gather and organize\\nrelevant information themselves; however, the reading com-\\n3. The term ‚Äúdocument‚Äù will henceforth refer to any text-based con-\\ntent subject to retrieve, including both long articles and short passages.\\narXiv:2308.07107v4  [cs.CL]  4 Sep 2024\\n2\\nRewriter\\nRetriever\\nReranker\\nNew Queries\\nCandidateDocumentsSelectedDocuments\\nReader\\nLarge Language Models\\nChatGPTLLaMA GLM\\nFlan-T5\\n ‚Ä¶\\nBLOOMResponse\\nSearch Context\\nQueryùëõ\\nQuery1\\nResponse1\\n‚ãØ\\nTraditional IR Components\\nSearch Agent\\nQuery2\\nResponse2\\n(1)\\n(2)\\nFig. 1. Overview of existing studies that apply LLMs into IR. (1) LLMs can be used to enhance traditional IR components,\\nsuch as query rewriter, retriever, reranker, and reader. (2) LLMs can also be used as search agents to perform multiple IR\\ntasks.\\nponent is an integral part of new IR systems such as New\\nBing,4 improving users‚Äô browsing experience and saving\\nvaluable time.\\nThe trajectory of IR has traversed a dynamic evolution,\\ntransitioning from its origins in term-based methods to the\\nintegration of neural models. Initially, IR was anchored in\\nterm-based methods [25] and Boolean logic, focusing on\\nkeyword matching for document retrieval. The paradigm\\ngradually shifted with the introduction of vector space mod-\\nels [26], unlocking the potential to capture nuanced semantic\\nrelationships between terms. This progression continued\\nwith statistical language models [27, 28], refining relevance\\nestimation through contextual and probabilistic considera-\\ntions. The influential BM25 algorithm [29] played an im-\\nportant role during this phase, revolutionizing relevance\\nranking by accounting for term frequency and document\\nlength variations. The most recent chapter in IR‚Äôs journey\\nis marked by the ascendancy of neural models [3, 30‚Äì\\n32]. These models excel at capturing intricate contextual\\ncues and semantic nuances, reshaping the landscape of IR.\\nHowever, these neural models still face challenges such as\\ndata scarcity, interpretability, and the potential generation of\\nplausible yet inaccurate responses. Thus, the evolution of IR\\ncontinues to be a journey of balancing traditional strengths\\n(such as the BM25 algorithm‚Äôs high efficiency) with the\\nremarkable capability (such as semantic understanding)\\nbrought about by modern neural architectures.\\nLarge language models (LLMs) have recently emerged as\\ntransformative forces across various research fields, such as\\nnatural language processing (NLP) [33‚Äì35], recommender\\nsystems [36‚Äì39], finance [40], and even molecule discov-\\nery [41]. These cutting-edge LLMs are primarily based on\\nthe Transformer architecture and undergo extensive pre-\\ntraining on diverse textual sources, including web pages,\\nresearch articles, books, and codes. As their scale continues\\nto expand (including both model size and data volume),\\nLLMs have demonstrated remarkable advances in their ca-\\npabilities. On the one hand, LLMs have exhibited unprece-\\ndented proficiency in language understanding and genera-\\ntion, resulting in responses that are more human-like and\\nbetter aligned with human intentions. On the other hand,\\n4. New Bing, https://www.bing.com/new\\nthe larger LLMs have shown impressive emergent abilities\\nwhen dealing with complex tasks [42], such as generaliza-\\ntion and reasoning skills. Leveraging the impressive power\\nof LLMs can undoubtedly improve the performance of IR\\nsystems. By incorporating these advanced language models,\\nIR systems can provide users with more accurate responses,\\nultimately reshaping the landscape of information access\\nand retrieval.\\nInitial efforts have been made to utilize the potential of\\nLLMs in the development of novel IR systems. Notably, in\\nterms of practical applications, New Bing is designed to\\nimprove the users‚Äô experience of using search engines by\\nextracting information from disparate web pages and con-\\ndensing it into concise summaries that serve as responses\\nto user-generated queries. In the research community, LLMs\\nhave proven useful within specific modules of IR systems\\n(such as retrievers), thereby enhancing the overall perfor-\\nmance of these systems. Due to the rapid evolution of LLM-\\nenhanced IR systems, it is essential to comprehensively\\nreview their most recent advancements and challenges.\\nOur survey provides an insightful exploration of the\\nintersection between LLMs and IR systems, covering key\\nperspectives such as query rewriters, retrievers, rerankers,\\nand readers (as shown in Figure 1). 5 We also include some\\nrecent studies that leverage LLMs as search agents to per-\\nform various IR tasks. This analysis enhances our under-\\nstanding of LLMs‚Äô potential and limitations in advancing\\nthe IR field. For this survey, we create a Github repository by\\ncollecting the relevant papers and resources about applying\\nLLMs for IR tasks (LLM4IR). 6 We will continue to update\\nthe repository with newer papers. This survey will also be\\nperiodically updated according to the development of this\\narea. We notice that there are several surveys for PLMs,\\nLLMs, and their applications ( e.g., AIGC or recommender\\nsystems) [43‚Äì49]. Compared with them, we focus on the\\ntechniques and methods for developing and applying LLMs\\nfor IR systems. In addition, we suggest reading the strategy\\n5. As yet, there has not been a formal definition for LLMs. In this pa-\\nper, we mainly focus on models with more than 1B parameters. We also\\nnotice that some methods do not rely on such strictly defined LLMs, but\\ndue to their representativeness, we still include an introduction to them\\nin this survey.\\n6. https://github.com/RUC-NLPIR/LLM4IR-Survey'}}}], 'role': 'user'}, 'invocation_id': 'e-6c079805-1a85-40d7-83b0-829f404e126f', 'author': 'research_analyst', 'actions': {'state_delta': {}, 'artifact_delta': {}, 'requested_auth_configs': {}, 'requested_tool_confirmations': {}}, 'id': '52b8ad5f-d3ac-4596-ab79-40ba783f5b8b', 'timestamp': 1763439384.653204}\n",
            "{'model_version': 'gemini-2.0-flash', 'content': {'parts': [{'text': \"The PDF was successfully read. Now, let's clean the extracted text and convert it to markdown using the `document_reader` tool.\\n\\n\"}, {'function_call': {'id': 'adk-0591a419-350d-41ad-b1e0-42fcfdc464d6', 'args': {'request': '1\\nLarge Language Models for Information\\nRetrieval: A Survey\\nYutao Zhu, Huaying Yuan, Shuting Wang, Jiongnan Liu, Wenhan Liu, Chenlong Deng\\nHaonan Chen, Zheng Liu, Zhicheng Dou, and Ji-Rong Wen\\nAbstract‚ÄîAs a primary means of information acquisition, information retrieval (IR) systems, such as search engines, have integrated\\nthemselves into our daily lives. These systems also serve as components of dialogue, question-answering, and recommender systems.\\nThe trajectory of IR has evolved dynamically from its origins in term-based methods to its integration with advanced neural models.\\nWhile the neural models excel at capturing complex contextual signals and semantic nuances, thereby reshaping the IR landscape,\\nthey still face challenges such as data scarcity, interpretability, and the generation of contextually plausible yet potentially inaccurate\\nresponses. This evolution requires a combination of both traditional methods (such as term-based sparse retrieval methods with rapid\\nresponse) and modern neural architectures (such as language models with powerful language understanding capacity). Meanwhile,\\nthe emergence of large language models (LLMs), typified by ChatGPT and GPT -4, has revolutionized natural language processing due\\nto their remarkable language understanding, generation, generalization, and reasoning abilities. Consequently, recent research has\\nsought to leverage LLMs to improve IR systems. Given the rapid evolution of this research trajectory, it is necessary to consolidate\\nexisting methodologies and provide nuanced insights through a comprehensive overview. In this survey, we delve into the confluence\\nof LLMs and IR systems, including crucial aspects such as query rewriters, retrievers, rerankers, and readers. Additionally, we explore\\npromising directions, such as search agents, within this expanding field.\\nIndex Terms‚ÄîLarge Language Models; Information Retrieval; Query Rewriter; Reranking; Reader; Fine-tuning; Prompting\\n‚ú¶\\n1 I NTRODUCTION\\nI\\nNFORMATION access is one of the fundamental daily\\nneeds of human beings. To fulfill the need for rapid\\nacquisition of desired information, various information re-\\ntrieval (IR) systems have been developed [1‚Äì4]. Prominent\\nexamples include search engines such as Google, Bing, and\\nBaidu, which serve as IR systems on the Internet, adept at\\nretrieving relevant web pages in response to user queries,\\nand provide convenient and efficient access to information\\non the Internet. It is worth noting that IR extends beyond\\nweb page retrieval. In dialogue systems (chatbots) [1, 5‚Äì\\n8], such as Microsoft Xiaoice [2], Apple Siri, 1 and Google\\nAssistant,2 IR systems play a crucial role in retrieving appro-\\npriate responses to user input utterances, thereby producing\\nnatural and fluent human-machine conversations. Similarly,\\nin question-answering systems [3, 9], IR systems are em-\\nployed to select relevant clues essential for addressing user\\nquestions effectively. In image search engines [4], IR systems\\nexcel at returning images that align with user input queries.\\nGiven the exponential growth of information, research and\\nindustry have become increasingly interested in the devel-\\nopment of effective IR systems.\\nThe core function of an IR system is retrieval, which aims\\nto determine the relevance between a user-issued query\\nand the content to be retrieved, including various types\\nof information such as texts, images, music, and more. For\\nAll authors except Zheng Liu are from Gaoling School of Artificial Intelligence\\nand School of Information, Renmin University of China. Zheng Liu is from\\nBeijing Academy of Artificial Intelligence, China.\\nContact e-mail: yutaozhu94@gmail.com, dou@ruc.edu.cn\\n1. Apple Siri, https://www.apple.com/siri/\\n2. Google Assistant, https://assistant.google.com/\\nthe scope of this survey, we concentrate solely on review-\\ning those text retrieval systems, in which query-document\\nrelevance is commonly measured by their matching score. 3\\nGiven that IR systems operate on extensive repositories,\\nthe efficiency of retrieval algorithms becomes of paramount\\nimportance. To improve the user experience, the retrieval\\nperformance is enhanced from both the upstream (query\\nreformulation) and downstream (reranking and reading)\\nperspectives. As an upstream technique, query reformu-\\nlation is designed to refine user queries so that they are\\nmore effective at retrieving relevant documents [10, 11].\\nWith the recent surge in the popularity of conversational\\nsearch, this technique has received increasing attention. On\\nthe downstream side, reranking approaches are developed\\nto further adjust the document ranking [12‚Äì14]. In contrast\\nto the retrieval stage, reranking is performed only on a\\nlimited set of relevant documents, already retrieved by the\\nretriever. Under this circumstance, the emphasis is placed\\non achieving higher performance rather than keeping higher\\nefficiency, allowing for the application of more complex ap-\\nproaches in the reranking process. Additionally, reranking\\ncan accommodate other specific requirements, such as per-\\nsonalization [15‚Äì18] and diversification [19‚Äì22]. Following\\nthe retrieval and reranking stages, a reading component is\\nincorporated to summarize the retrieved documents and de-\\nliver a concise document to users [23, 24]. While traditional\\nIR systems typically require users to gather and organize\\nrelevant information themselves; however, the reading com-\\n3. The term ‚Äúdocument‚Äù will henceforth refer to any text-based con-\\ntent subject to retrieve, including both long articles and short passages.\\narXiv:2308.07107v4  [cs.CL]  4 Sep 2024\\n2\\nRewriter\\nRetriever\\nReranker\\nNew Queries\\nCandidateDocumentsSelectedDocuments\\nReader\\nLarge Language Models\\nChatGPTLLaMA GLM\\nFlan-T5\\n ‚Ä¶\\nBLOOMResponse\\nSearch Context\\nQueryùëõ\\nQuery1\\nResponse1\\n‚ãØ\\nTraditional IR Components\\nSearch Agent\\nQuery2\\nResponse2\\n(1)\\n(2)\\nFig. 1. Overview of existing studies that apply LLMs into IR. (1) LLMs can be used to enhance traditional IR components,\\nsuch as query rewriter, retriever, reranker, and reader. (2) LLMs can also be used as search agents to perform multiple IR\\ntasks.\\nponent is an integral part of new IR systems such as New\\nBing,4 improving users‚Äô browsing experience and saving\\nvaluable time.\\nThe trajectory of IR has traversed a dynamic evolution,\\ntransitioning from its origins in term-based methods to the\\nintegration of neural models. Initially, IR was anchored in\\nterm-based methods [25] and Boolean logic, focusing on\\nkeyword matching for document retrieval. The paradigm\\ngradually shifted with the introduction of vector space mod-\\nels [26], unlocking the potential to capture nuanced semantic\\nrelationships between terms. This progression continued\\nwith statistical language models [27, 28], refining relevance\\nestimation through contextual and probabilistic considera-\\ntions. The influential BM25 algorithm [29] played an im-\\nportant role during this phase, revolutionizing relevance\\nranking by accounting for term frequency and document\\nlength variations. The most recent chapter in IR‚Äôs journey\\nis marked by the ascendancy of neural models [3, 30‚Äì\\n32]. These models excel at capturing intricate contextual\\ncues and semantic nuances, reshaping the landscape of IR.\\nHowever, these neural models still face challenges such as\\ndata scarcity, interpretability, and the potential generation of\\nplausible yet inaccurate responses. Thus, the evolution of IR\\ncontinues to be a journey of balancing traditional strengths\\n(such as the BM25 algorithm‚Äôs high efficiency) with the\\nremarkable capability (such as semantic understanding)\\nbrought about by modern neural architectures.\\nLarge language models (LLMs) have recently emerged as\\ntransformative forces across various research fields, such as\\nnatural language processing (NLP) [33‚Äì35], recommender\\nsystems [36‚Äì39], finance [40], and even molecule discov-\\nery [41]. These cutting-edge LLMs are primarily based on\\nthe Transformer architecture and undergo extensive pre-\\ntraining on diverse textual sources, including web pages,\\nresearch articles, books, and codes. As their scale continues\\nto expand (including both model size and data volume),\\nLLMs have demonstrated remarkable advances in their ca-\\npabilities. On the one hand, LLMs have exhibited unprece-\\ndented proficiency in language understanding and genera-\\ntion, resulting in responses that are more human-like and\\nbetter aligned with human intentions. On the other hand,\\n4. New Bing, https://www.bing.com/new\\nthe larger LLMs have shown impressive emergent abilities\\nwhen dealing with complex tasks [42], such as generaliza-\\ntion and reasoning skills. Leveraging the impressive power\\nof LLMs can undoubtedly improve the performance of IR\\nsystems. By incorporating these advanced language models,\\nIR systems can provide users with more accurate responses,\\nultimately reshaping the landscape of information access\\nand retrieval.\\nInitial efforts have been made to utilize the potential of\\nLLMs in the development of novel IR systems. Notably, in\\nterms of practical applications, New Bing is designed to\\nimprove the users‚Äô experience of using search engines by\\nextracting information from disparate web pages and con-\\ndensing it into concise summaries that serve as responses\\nto user-generated queries. In the research community, LLMs\\nhave proven useful within specific modules of IR systems\\n(such as retrievers), thereby enhancing the overall perfor-\\nmance of these systems. Due to the rapid evolution of LLM-\\nenhanced IR systems, it is essential to comprehensively\\nreview their most recent advancements and challenges.\\nOur survey provides an insightful exploration of the\\nintersection between LLMs and IR systems, covering key\\nperspectives such as query rewriters, retrievers, rerankers,\\nand readers (as shown in Figure 1). 5 We also include some\\nrecent studies that leverage LLMs as search agents to per-\\nform various IR tasks. This analysis enhances our under-\\nstanding of LLMs‚Äô potential and limitations in advancing\\nthe IR field. For this survey, we create a Github repository by\\ncollecting the relevant papers and resources about applying\\nLLMs for IR tasks (LLM4IR). 6 We will continue to update\\nthe repository with newer papers. This survey will also be\\nperiodically updated according to the development of this\\narea. We notice that there are several surveys for PLMs,\\nLLMs, and their applications ( e.g., AIGC or recommender\\nsystems) [43‚Äì49]. Compared with them, we focus on the\\ntechniques and methods for developing and applying LLMs\\nfor IR systems. In addition, we suggest reading the strategy\\n5. As yet, there has not been a formal definition for LLMs. In this pa-\\nper, we mainly focus on models with more than 1B parameters. We also\\nnotice that some methods do not rely on such strictly defined LLMs, but\\ndue to their representativeness, we still include an introduction to them\\nin this survey.\\n6. https://github.com/RUC-NLPIR/LLM4IR-Survey'}, 'name': 'document_reader'}}], 'role': 'model'}, 'finish_reason': 'STOP', 'usage_metadata': {'candidates_token_count': 2439, 'candidates_tokens_details': [{'modality': 'TEXT', 'token_count': 2439}], 'prompt_token_count': 3081, 'prompt_tokens_details': [{'modality': 'TEXT', 'token_count': 3081}], 'total_token_count': 5520, 'traffic_type': 'ON_DEMAND'}, 'avg_logprobs': -0.0020045559637954166, 'invocation_id': 'e-6c079805-1a85-40d7-83b0-829f404e126f', 'author': 'research_analyst', 'actions': {'state_delta': {}, 'artifact_delta': {}, 'requested_auth_configs': {}, 'requested_tool_confirmations': {}}, 'long_running_tool_ids': [], 'id': 'abedb308-f8dd-463b-8e06-43c1832f5176', 'timestamp': 1763439384.759109}\n",
            "{'content': {'parts': [{'function_response': {'id': 'adk-0591a419-350d-41ad-b1e0-42fcfdc464d6', 'name': 'document_reader', 'response': {'result': '```markdown\\n## Large Language Models for Information Retrieval: A Survey\\n\\n**Authors:** Yutao Zhu, Huaying Yuan, Shuting Wang, Jiongnan Liu, Wenhan Liu, Chenlong Deng, Haonan Chen, Zheng Liu, Zhicheng Dou, and Ji-Rong Wen\\n\\n**Abstract:** As a primary means of information acquisition, information retrieval (IR) systems, such as search engines, have integrated themselves into our daily lives. These systems also serve as components of dialogue, question-answering, and recommender systems. The trajectory of IR has evolved dynamically from its origins in term-based methods to its integration with advanced neural models. While the neural models excel at capturing complex contextual signals and semantic nuances, thereby reshaping the IR landscape, they still face challenges such as data scarcity, interpretability, and the generation of contextually plausible yet potentially inaccurate responses. This evolution requires a combination of both traditional methods (such as term-based sparse retrieval methods with rapid response) and modern neural architectures (such as language models with powerful language understanding capacity). Meanwhile, the emergence of large language models (LLMs), typified by ChatGPT and GPT -4, has revolutionized natural language processing due to their remarkable language understanding, generation, generalization, and reasoning abilities. Consequently, recent research has sought to leverage LLMs to improve IR systems. Given the rapid evolution of this research trajectory, it is necessary to consolidate existing methodologies and provide nuanced insights through a comprehensive overview. In this survey, we delve into the confluence of LLMs and IR systems, including crucial aspects such as query rewriters, retrievers, rerankers, and readers. Additionally, we explore promising directions, such as search agents, within this expanding field.\\n\\n**Index Terms:** Large Language Models; Information Retrieval; Query Rewriter; Reranking; Reader; Fine-tuning; Prompting\\n\\n## 1 INTRODUCTION\\n\\nINFORMATION access is one of the fundamental daily needs of human beings. To fulfill the need for rapid acquisition of desired information, various information retrieval (IR) systems have been developed [1‚Äì4]. Prominent examples include search engines such as Google, Bing, and Baidu, which serve as IR systems on the Internet, adept at retrieving relevant web pages in response to user queries, and provide convenient and efficient access to information on the Internet. It is worth noting that IR extends beyond web page retrieval. In dialogue systems (chatbots) [1, 5‚Äì8], such as Microsoft Xiaoice [2], Apple Siri, 1 and Google Assistant,2 IR systems play a crucial role in retrieving appropriate responses to user input utterances, thereby producing natural and fluent human-machine conversations. Similarly, in question-answering systems [3, 9], IR systems are employed to select relevant clues essential for addressing user questions effectively. In image search engines [4], IR systems excel at returning images that align with user input queries. Given the exponential growth of information, research and industry have become increasingly interested in the development of effective IR systems.\\n\\nThe core function of an IR system is retrieval, which aims to determine the relevance between a user-issued query and the content to be retrieved, including various types of information such as texts, images, music, and more. For the scope of this survey, we concentrate solely on reviewing those text retrieval systems, in which query-document relevance is commonly measured by their matching score. 3 Given that IR systems operate on extensive repositories, the efficiency of retrieval algorithms becomes of paramount importance. To improve the user experience, the retrieval performance is enhanced from both the upstream (query reformulation) and downstream (reranking and reading) perspectives. As an upstream technique, query reformulation is designed to refine user queries so that they are more effective at retrieving relevant documents [10, 11]. With the recent surge in the popularity of conversational search, this technique has received increasing attention. On the downstream side, reranking approaches are developed to further adjust the document ranking [12‚Äì14]. In contrast to the retrieval stage, reranking is performed only on a limited set of relevant documents, already retrieved by the retriever. Under this circumstance, the emphasis is placed on achieving higher performance rather than keeping higher efficiency, allowing for the application of more complex approaches in the reranking process. Additionally, reranking can accommodate other specific requirements, such as personalization [15‚Äì18] and diversification [19‚Äì22]. Following the retrieval and reranking stages, a reading component is incorporated to summarize the retrieved documents and deliver a concise document to users [23, 24]. While traditional IR systems typically require users to gather and organize relevant information themselves; however, the reading com-\\n\\n3. The term ‚Äúdocument‚Äù will henceforth refer to any text-based content subject to retrieve, including both long articles and short passages.\\n\\nThe trajectory of IR has traversed a dynamic evolution, transitioning from its origins in term-based methods to the integration of neural models. Initially, IR was anchored in term-based methods [25] and Boolean logic, focusing on keyword matching for document retrieval. The paradigm gradually shifted with the introduction of vector space models [26], unlocking the potential to capture nuanced semantic relationships between terms. This progression continued with statistical language models [27, 28], refining relevance estimation through contextual and probabilistic considerations. The influential BM25 algorithm [29] played an important role during this phase, revolutionizing relevance ranking by accounting for term frequency and document length variations. The most recent chapter in IR‚Äôs journey is marked by the ascendancy of neural models [3, 30‚Äì32]. These models excel at capturing intricate contextual cues and semantic nuances, reshaping the landscape of IR. However, these neural models still face challenges such as data scarcity, interpretability, and the potential generation of plausible yet inaccurate responses. Thus, the evolution of IR continues to be a journey of balancing traditional strengths (such as the BM25 algorithm‚Äôs high efficiency) with the remarkable capability (such as semantic understanding) brought about by modern neural architectures.\\n\\nLarge language models (LLMs) have recently emerged as transformative forces across various research fields, such as natural language processing (NLP) [33‚Äì35], recommender systems [36‚Äì39], finance [40], and even molecule discovery [41]. These cutting-edge LLMs are primarily based on the Transformer architecture and undergo extensive pre-training on diverse textual sources, including web pages, research articles, books, and codes. As their scale continues to expand (including both model size and data volume), LLMs have demonstrated remarkable advances in their capabilities. On the one hand, LLMs have exhibited unprecedented proficiency in language understanding and generation, resulting in responses that are more human-like and better aligned with human intentions. On the other hand, the larger LLMs have shown impressive emergent abilities when dealing with complex tasks [42], such as generalization and reasoning skills. Leveraging the impressive power of LLMs can undoubtedly improve the performance of IR systems. By incorporating these advanced language models, IR systems can provide users with more accurate responses, ultimately reshaping the landscape of information access and retrieval.\\n\\nInitial efforts have been made to utilize the potential of LLMs in the development of novel IR systems. Notably, in terms of practical applications, New Bing is designed to improve the users‚Äô experience of using search engines by extracting information from disparate web pages and condensing it into concise summaries that serve as responses to user-generated queries. In the research community, LLMs have proven useful within specific modules of IR systems (such as retrievers), thereby enhancing the overall performance of these systems. Due to the rapid evolution of LLM-enhanced IR systems, it is essential to comprehensively review their most recent advancements and challenges.\\n\\nOur survey provides an insightful exploration of the intersection between LLMs and IR systems, covering key perspectives such as query rewriters, retrievers, rerankers, and readers (as shown in Figure 1). 5 We also include some recent studies that leverage LLMs as search agents to perform various IR tasks. This analysis enhances our understanding of LLMs‚Äô potential and limitations in advancing the IR field. For this survey, we create a Github repository by collecting the relevant papers and resources about applying LLMs for IR tasks (LLM4IR). 6 We will continue to update the repository with newer papers. This survey will also be periodically updated according to the development of this area. We notice that there are several surveys for PLMs, LLMs, and their applications ( e.g., AIGC or recommender systems) [43‚Äì49]. Compared with them, we focus on the techniques and methods for developing and applying LLMs for IR systems. In addition, we suggest reading the strategy\\n\\n5. As yet, there has not been a formal definition for LLMs. In this paper, we mainly focus on models with more than 1B parameters. We also notice that some methods do not rely on such strictly defined LLMs, but due to their representativeness, we still include an introduction to them in this survey.\\n6. https://github.com/RUC-NLPIR/LLM4IR-Survey\\n```'}}}], 'role': 'user'}, 'invocation_id': 'e-6c079805-1a85-40d7-83b0-829f404e126f', 'author': 'research_analyst', 'actions': {'state_delta': {}, 'artifact_delta': {}, 'requested_auth_configs': {}, 'requested_tool_confirmations': {}}, 'id': '282aec7d-f35b-4f94-af25-6ed2da256271', 'timestamp': 1763439417.32726}\n",
            "{'model_version': 'gemini-2.0-flash', 'content': {'parts': [{'text': \"The document has been successfully converted to markdown format. Now, let's build a context from this markdown using the `context_builder` tool to get a more focused and detailed understanding of the survey.\\n\\n\"}, {'function_call': {'id': 'adk-e698fdd1-279a-4eee-8108-0077d528fff2', 'args': {'request': '```markdown\\n## Large Language Models for Information Retrieval: A Survey\\n\\n**Authors:** Yutao Zhu, Huaying Yuan, Shuting Wang, Jiongnan Liu, Wenhan Liu, Chenlong Deng, Haonan Chen, Zheng Liu, Zhicheng Dou, and Ji-Rong Wen\\n\\n**Abstract:** As a primary means of information acquisition, information retrieval (IR) systems, such as search engines, have integrated themselves into our daily lives. These systems also serve as components of dialogue, question-answering, and recommender systems. The trajectory of IR has evolved dynamically from its origins in term-based methods to its integration with advanced neural models. While the neural models excel at capturing complex contextual signals and semantic nuances, thereby reshaping the IR landscape, they still face challenges such as data scarcity, interpretability, and the generation of contextually plausible yet potentially inaccurate responses. This evolution requires a combination of both traditional methods (such as term-based sparse retrieval methods with rapid response) and modern neural architectures (such as language models with powerful language understanding capacity). Meanwhile, the emergence of large language models (LLMs), typified by ChatGPT and GPT -4, has revolutionized natural language processing due to their remarkable language understanding, generation, generalization, and reasoning abilities. Consequently, recent research has sought to leverage LLMs to improve IR systems. Given the rapid evolution of this research trajectory, it is necessary to consolidate existing methodologies and provide nuanced insights through a comprehensive overview. In this survey, we delve into the confluence of LLMs and IR systems, including crucial aspects such as query rewriters, retrievers, rerankers, and readers. Additionally, we explore promising directions, such as search agents, within this expanding field.\\n\\n**Index Terms:** Large Language Models; Information Retrieval; Query Rewriter; Reranking; Reader; Fine-tuning; Prompting\\n\\n## 1 INTRODUCTION\\n\\nINFORMATION access is one of the fundamental daily needs of human beings. To fulfill the need for rapid acquisition of desired information, various information retrieval (IR) systems have been developed [1‚Äì4]. Prominent examples include search engines such as Google, Bing, and Baidu, which serve as IR systems on the Internet, adept at retrieving relevant web pages in response to user queries, and provide convenient and efficient access to information on the Internet. It is worth noting that IR extends beyond web page retrieval. In dialogue systems (chatbots) [1, 5‚Äì8], such as Microsoft Xiaoice [2], Apple Siri, 1 and Google Assistant,2 IR systems play a crucial role in retrieving appropriate responses to user input utterances, thereby producing natural and fluent human-machine conversations. Similarly, in question-answering systems [3, 9], IR systems are employed to select relevant clues essential for addressing user questions effectively. In image search engines [4], IR systems excel at returning images that align with user input queries. Given the exponential growth of information, research and industry have become increasingly interested in the development of effective IR systems.\\n\\nThe core function of an IR system is retrieval, which aims to determine the relevance between a user-issued query and the content to be retrieved, including various types of information such as texts, images, music, and more. For the scope of this survey, we concentrate solely on reviewing those text retrieval systems, in which query-document relevance is commonly measured by their matching score. 3 Given that IR systems operate on extensive repositories, the efficiency of retrieval algorithms becomes of paramount importance. To improve the user experience, the retrieval performance is enhanced from both the upstream (query reformulation) and downstream (reranking and reading) perspectives. As an upstream technique, query reformulation is designed to refine user queries so that they are more effective at retrieving relevant documents [10, 11]. With the recent surge in the popularity of conversational search, this technique has received increasing attention. On the downstream side, reranking approaches are developed to further adjust the document ranking [12‚Äì14]. In contrast to the retrieval stage, reranking is performed only on a limited set of relevant documents, already retrieved by the retriever. Under this circumstance, the emphasis is placed on achieving higher performance rather than keeping higher efficiency, allowing for the application of more complex approaches in the reranking process. Additionally, reranking can accommodate other specific requirements, such as personalization [15‚Äì18] and diversification [19‚Äì22]. Following the retrieval and reranking stages, a reading component is incorporated to summarize the retrieved documents and deliver a concise document to users [23, 24]. While traditional IR systems typically require users to gather and organize relevant information themselves; however, the reading com-\\n\\n3. The term ‚Äúdocument‚Äù will henceforth refer to any text-based content subject to retrieve, including both long articles and short passages.\\n\\nThe trajectory of IR has traversed a dynamic evolution, transitioning from its origins in term-based methods to the integration of neural models. Initially, IR was anchored in term-based methods [25] and Boolean logic, focusing on keyword matching for document retrieval. The paradigm gradually shifted with the introduction of vector space models [26], unlocking the potential to capture nuanced semantic relationships between terms. This progression continued with statistical language models [27, 28], refining relevance estimation through contextual and probabilistic considerations. The influential BM25 algorithm [29] played an important role during this phase, revolutionizing relevance ranking by accounting for term frequency and document length variations. The most recent chapter in IR‚Äôs journey is marked by the ascendancy of neural models [3, 30‚Äì32]. These models excel at capturing intricate contextual cues and semantic nuances, reshaping the landscape of IR. However, these neural models still face challenges such as data scarcity, interpretability, and the potential generation of plausible yet inaccurate responses. Thus, the evolution of IR continues to be a journey of balancing traditional strengths (such as the BM25 algorithm‚Äôs high efficiency) with the remarkable capability (such as semantic understanding) brought about by modern neural architectures.\\n\\nLarge language models (LLMs) have recently emerged as transformative forces across various research fields, such as natural language processing (NLP) [33‚Äì35], recommender systems [36‚Äì39], finance [40], and even molecule discovery [41]. These cutting-edge LLMs are primarily based on the Transformer architecture and undergo extensive pre-training on diverse textual sources, including web pages, research articles, books, and codes. As their scale continues to expand (including both model size and data volume), LLMs have demonstrated remarkable advances in their capabilities. On the one hand, LLMs have exhibited unprecedented proficiency in language understanding and generation, resulting in responses that are more human-like and better aligned with human intentions. On the other hand, the larger LLMs have shown impressive emergent abilities when dealing with complex tasks [42], such as generalization and reasoning skills. Leveraging the impressive power of LLMs can undoubtedly improve the performance of IR systems. By incorporating these advanced language models, IR systems can provide users with more accurate responses, ultimately reshaping the landscape of information access and retrieval.\\n\\nInitial efforts have been made to utilize the potential of LLMs in the development of novel IR systems. Notably, in terms of practical applications, New Bing is designed to improve the users‚Äô experience of using search engines by extracting information from disparate web pages and condensing it into concise summaries that serve as responses to user-generated queries. In the research community, LLMs have proven useful within specific modules of IR systems (such as retrievers), thereby enhancing the overall performance of these systems. Due to the rapid evolution of LLM-enhanced IR systems, it is essential to comprehensively review their most recent advancements and challenges.\\n\\nOur survey provides an insightful exploration of the intersection between LLMs and IR systems, covering key perspectives such as query rewriters, retrievers, rerankers, and readers (as shown in Figure 1). 5 We also include some recent studies that leverage LLMs as search agents to perform various IR tasks. This analysis enhances our understanding of LLMs‚Äô potential and limitations in advancing the IR field. For this survey, we create a Github repository by collecting the relevant papers and resources about applying LLMs for IR tasks (LLM4IR). 6 We will continue to update the repository with newer papers. This survey will also be periodically updated according to the development of this area. We notice that there are several surveys for PLMs, LLMs, and their applications ( e.g., AIGC or recommender systems) [43‚Äì49]. Compared with them, we focus on the techniques and methods for developing and applying LLMs for IR systems. In addition, we suggest reading the strategy\\n\\n5. As yet, there has not been a formal definition for LLMs. In this paper, we mainly focus on models with more than 1B parameters. We also notice that some methods do not rely on such strictly defined LLMs, but due to their representativeness, we still include an introduction to them in this survey.\\n6. https://github.com/RUC-NLPIR/LLM4IR-Survey\\n```'}, 'name': 'context_builder'}}], 'role': 'model'}, 'finish_reason': 'STOP', 'usage_metadata': {'candidates_token_count': 1928, 'candidates_tokens_details': [{'modality': 'TEXT', 'token_count': 1928}], 'prompt_token_count': 7406, 'prompt_tokens_details': [{'modality': 'TEXT', 'token_count': 7406}], 'total_token_count': 9334, 'traffic_type': 'ON_DEMAND'}, 'avg_logprobs': -0.0039821121207906, 'citation_metadata': {'citations': [{'end_index': 915, 'start_index': 508, 'uri': 'https://janaganamana.net/mana/Articles?q=Chenlong%20He'}, {'end_index': 1133, 'start_index': 869, 'uri': 'https://janaganamana.net/mana/Articles?q=Chenlong%20He'}, {'end_index': 1405, 'start_index': 1172, 'uri': 'https://paperswithcode.com/author/yutao-zhu'}, {'end_index': 2032, 'start_index': 1288, 'title': 'Your prompt'}, {'end_index': 2146, 'start_index': 1934, 'uri': 'https://janaganamana.net/mana/Articles?q=Chenlong%20He'}, {'end_index': 3501, 'start_index': 2360, 'title': 'Your prompt'}, {'end_index': 5355, 'start_index': 3512, 'title': 'Your prompt'}, {'end_index': 6884, 'start_index': 5513, 'title': 'Your prompt'}, {'end_index': 7628, 'start_index': 6897, 'title': 'Your prompt'}, {'end_index': 8674, 'start_index': 8110, 'title': 'Your prompt'}, {'end_index': 8781, 'start_index': 8553, 'uri': 'https://arxiv.org/abs/2308.07107'}, {'end_index': 9299, 'start_index': 8794, 'uri': 'https://bytez.com/docs/arxiv/2308.07107/paper?related=datasets'}, {'end_index': 9609, 'start_index': 9330, 'uri': 'https://bytez.com/docs/arxiv/2308.07107/paper?related=datasets'}, {'end_index': 10071, 'start_index': 9776, 'uri': 'https://arxiv.org/abs/2308.07107'}]}, 'invocation_id': 'e-6c079805-1a85-40d7-83b0-829f404e126f', 'author': 'research_analyst', 'actions': {'state_delta': {}, 'artifact_delta': {}, 'requested_auth_configs': {}, 'requested_tool_confirmations': {}}, 'long_running_tool_ids': [], 'id': 'ae1a64a9-562c-4c35-88e9-7a4dffd29214', 'timestamp': 1763439417.551892}\n",
            "{'content': {'parts': [{'function_response': {'id': 'adk-e698fdd1-279a-4eee-8108-0077d528fff2', 'name': 'context_builder', 'response': {'result': \"This survey explores the burgeoning intersection of Large Language Models (LLMs) and Information Retrieval (IR) systems, driven by the need for more effective information access. Traditional IR systems, evolving from term-based methods like BM25 to neural models, face challenges in capturing semantic nuances, dealing with data scarcity, and ensuring response accuracy. LLMs, exemplified by ChatGPT and GPT-4, offer revolutionary capabilities in language understanding, generation, and reasoning, prompting their integration into IR to address these limitations.\\n\\nThe core function of an IR system is retrieval, assessing the relevance between a user query and retrievable content, often measured by a matching score. Efficiency is paramount due to the scale of repositories. Techniques like query reformulation refine user queries for better retrieval, especially relevant in conversational search. Reranking adjusts document rankings, prioritizing performance over efficiency by applying complex approaches on a limited set of retrieved documents, accommodating personalization and diversification. Finally, readers summarize retrieved documents, delivering concise information.\\n\\nLLMs, based on Transformer architecture and pre-trained on extensive text data, demonstrate unprecedented proficiency in understanding and generating human-like responses. Their emergent abilities in generalization and reasoning make them valuable assets for enhancing IR systems.\\n\\nThe survey delves into specific applications of LLMs within IR pipelines, focusing on query rewriters, retrievers, rerankers, and readers. LLMs are used to rewrite queries to improve retrieval effectiveness. LLMs enhance retrieval by better understanding semantic relationships between queries and documents. Reranking benefits from LLMs' ability to refine document ordering based on contextual understanding. Finally, LLMs are utilized to read and summarize documents to the user. Additionally, the survey explores the emerging concept of search agents, where LLMs autonomously perform various IR tasks.\\n\\nThe authors maintain a GitHub repository (LLM4IR) to collect relevant papers and resources about applying LLMs for IR tasks.\\n\"}}}], 'role': 'user'}, 'invocation_id': 'e-6c079805-1a85-40d7-83b0-829f404e126f', 'author': 'research_analyst', 'actions': {'state_delta': {}, 'artifact_delta': {}, 'requested_auth_configs': {}, 'requested_tool_confirmations': {}}, 'id': '5e835e1a-6314-46e0-a29c-94a1be3815e4', 'timestamp': 1763439437.198647}\n",
            "{'model_version': 'gemini-2.0-flash', 'content': {'parts': [{'text': \"Okay, I have the context now. Let's create an initial summary using the `summarizer` tool.\\n\\n\"}, {'function_call': {'id': 'adk-570eff48-1656-4ccc-938d-bfdb4104b644', 'args': {'request': \"This survey explores the burgeoning intersection of Large Language Models (LLMs) and Information Retrieval (IR) systems, driven by the need for more effective information access. Traditional IR systems, evolving from term-based methods like BM25 to neural models, face challenges in capturing semantic nuances, dealing with data scarcity, and ensuring response accuracy. LLMs, exemplified by ChatGPT and GPT-4, offer revolutionary capabilities in language understanding, generation, and reasoning, prompting their integration into IR to address these limitations.\\n\\nThe core function of an IR system is retrieval, assessing the relevance between a user query and retrievable content, often measured by a matching score. Efficiency is paramount due to the scale of repositories. Techniques like query reformulation refine user queries for better retrieval, especially relevant in conversational search. Reranking adjusts document rankings, prioritizing performance over efficiency by applying complex approaches on a limited set of retrieved documents, accommodating personalization and diversification. Finally, readers summarize retrieved documents, delivering concise information.\\n\\nLLMs, based on Transformer architecture and pre-trained on extensive text data, demonstrate unprecedented proficiency in understanding and generating human-like responses. Their emergent abilities in generalization and reasoning make them valuable assets for enhancing IR systems.\\n\\nThe survey delves into specific applications of LLMs within IR pipelines, focusing on query rewriters, retrievers, rerankers, and readers. LLMs are used to rewrite queries to improve retrieval effectiveness. LLMs enhance retrieval by better understanding semantic relationships between queries and documents. Reranking benefits from LLMs' ability to refine document ordering based on contextual understanding. Finally, LLMs are utilized to read and summarize documents to the user. Additionally, the survey explores the emerging concept of search agents, where LLMs autonomously perform various IR tasks.\\n\\nThe authors maintain a GitHub repository (LLM4IR) to collect relevant papers and resources about applying LLMs for IR tasks.\"}, 'name': 'summarizer'}}], 'role': 'model'}, 'finish_reason': 'STOP', 'usage_metadata': {'candidates_token_count': 406, 'candidates_tokens_details': [{'modality': 'TEXT', 'token_count': 406}], 'prompt_token_count': 9718, 'prompt_tokens_details': [{'modality': 'TEXT', 'token_count': 9718}], 'total_token_count': 10124, 'traffic_type': 'ON_DEMAND'}, 'avg_logprobs': -0.017878706232080318, 'invocation_id': 'e-6c079805-1a85-40d7-83b0-829f404e126f', 'author': 'research_analyst', 'actions': {'state_delta': {}, 'artifact_delta': {}, 'requested_auth_configs': {}, 'requested_tool_confirmations': {}}, 'long_running_tool_ids': [], 'id': '1efcc984-d9f6-4d50-8248-bff04f9c3a27', 'timestamp': 1763439437.315005}\n",
            "{'content': {'parts': [{'function_response': {'id': 'adk-570eff48-1656-4ccc-938d-bfdb4104b644', 'name': 'summarizer', 'response': {'result': \"Okay, here's a student-friendly summary of the research paper, focusing on the key aspects and using clear, simple language:\\n\\n**1. Title:** Large Language Models for Information Retrieval: A Survey\\n\\n**2. Problem:** Traditional search engines (Information Retrieval or IR systems) struggle with understanding the real meaning behind search queries, dealing with limited training data, and giving accurate answers. They need a boost to become more effective.\\n\\n**3. Background / Motivation:**  Think of Google search. It's pretty good, but sometimes it misses the point or doesn't quite understand what you're *really* asking. Large Language Models (LLMs) like ChatGPT are super smart at understanding and using language. Researchers are exploring how to use these LLMs to make search engines much better. LLMs can capture the *nuances* of language, where older systems often just look for keywords.\\n\\n**4. Method / Model:** This paper is a *survey*. That means it looks at a lot of different research papers and projects that are trying to combine LLMs and IR systems. It examines how LLMs can be plugged into different parts of the search process:\\n*   **Query Rewriting:** LLMs rephrase your search query to make it clearer for the search engine.\\n*   **Retrieval:** LLMs help the system find the most relevant documents in the first place.\\n*   **Reranking:** LLMs re-order the search results to put the best ones at the top.\\n*   **Reading/Summarization:** LLMs read the retrieved documents and create short summaries for you.\\n*   **Search Agents:** LLMs can act as autonomous agents that handle a variety of search tasks.\\n\\n**5. Dataset / Inputs:** This is a survey paper, so there's no single dataset. However, the papers it reviews use standard information retrieval datasets (e.g., collections of web pages, scientific articles, etc.) and user queries. The *input* to these combined systems is typically a user's search query.\\n\\n**6. Results:** This is a survey, so there is no single result. However, the survey highlights that LLMs *do* show promise in improving search results. For example, using LLMs to rewrite queries or re-rank documents often leads to more relevant results compared to traditional methods. The effectiveness depends on the specific task and how the LLM is integrated.\\n\\n**7. Strengths:**\\n*   **Clear Overview:** Provides a good overview of how LLMs are being used in different parts of the information retrieval process.\\n*   **Comprehensive:** Covers query rewriting, retrieval, re-ranking, reading/summarization, and the emerging area of search agents.\\n*   **Practical Focus:** Highlights the practical applications of LLMs for improving search.\\n*   **LLM4IR Repository**: The authors are actively curating a GitHub repository which is a useful resource.\\n\\n**8. Limitations:**\\n*   **Rapidly Evolving Field:** The field is changing *very* quickly. So some of the specific techniques discussed might become outdated fast.\\n*   **Cost & Efficiency:** LLMs can be computationally expensive, which can be a problem for large-scale search engines. The survey acknowledges that efficiency is crucial for IR systems.\\n*   **Bias and Fairness:** Like any AI system, LLMs can have biases that affect search results. This is an ongoing challenge.\\n\\n**9. Key Takeaways:**\\n\\n*   LLMs are powerful tools for understanding and generating language.\\n*   They can be used to improve various parts of the information retrieval process.\\n*   Query rewriting, retrieval, and re-ranking are key areas where LLMs can help.\\n*   Search agents are an emerging area with the potential for more automated search experiences.\\n*   Efficiency and cost are important considerations when using LLMs in search engines.\\n*   Bias in LLMs is a concern that needs to be addressed.\\n*   This is an active research area with lots of ongoing development.\\n*   LLMs can understand semantic relationships between queries and documents\\n\\n**10. Overall Conclusion:**\\n\\nThis survey shows that Large Language Models have the potential to significantly improve search engines and information retrieval systems. By using LLMs in different ways, researchers are making progress towards search engines that are better at understanding what we're really looking for and giving us more relevant and accurate results. However, there are still challenges to overcome, such as the computational cost and potential biases of LLMs. As LLMs continue to evolve, we can expect to see even more innovative ways to use them in search and information retrieval.\\n\"}}}], 'role': 'user'}, 'invocation_id': 'e-6c079805-1a85-40d7-83b0-829f404e126f', 'author': 'research_analyst', 'actions': {'state_delta': {}, 'artifact_delta': {}, 'requested_auth_configs': {}, 'requested_tool_confirmations': {}}, 'id': '93716ff0-6eb9-4b79-8186-3bf8750a5f25', 'timestamp': 1763439452.970356}\n",
            "{'model_version': 'gemini-2.0-flash', 'content': {'parts': [{'text': 'Now that I have the initial summary, I will evaluate it using the `evaluator` tool, along with the context, to identify any potential issues or areas for improvement.\\n\\n'}, {'function_call': {'id': 'adk-51398de8-f309-48ac-8d3a-97ce72e6c698', 'args': {'request': \"Context: This survey explores the burgeoning intersection of Large Language Models (LLMs) and Information Retrieval (IR) systems, driven by the need for more effective information access. Traditional IR systems, evolving from term-based methods like BM25 to neural models, face challenges in capturing semantic nuances, dealing with data scarcity, and ensuring response accuracy. LLMs, exemplified by ChatGPT and GPT-4, offer revolutionary capabilities in language understanding, generation, and reasoning, prompting their integration into IR to address these limitations.\\n\\nThe core function of an IR system is retrieval, assessing the relevance between a user query and retrievable content, often measured by a matching score. Efficiency is paramount due to the scale of repositories. Techniques like query reformulation refine user queries for better retrieval, especially relevant in conversational search. Reranking adjusts document rankings, prioritizing performance over efficiency by applying complex approaches on a limited set of retrieved documents, accommodating personalization and diversification. Finally, readers summarize retrieved documents, delivering concise information.\\n\\nLLMs, based on Transformer architecture and pre-trained on extensive text data, demonstrate unprecedented proficiency in understanding and generating human-like responses. Their emergent abilities in generalization and reasoning make them valuable assets for enhancing IR systems.\\n\\nThe survey delves into specific applications of LLMs within IR pipelines, focusing on query rewriters, retrievers, rerankers, and readers. LLMs are used to rewrite queries to improve retrieval effectiveness. LLMs enhance retrieval by better understanding semantic relationships between queries and documents. Reranking benefits from LLMs' ability to refine document ordering based on contextual understanding. Finally, LLMs are utilized to read and summarize documents to the user. Additionally, the survey explores the emerging concept of search agents, where LLMs autonomously perform various IR tasks.\\n\\nThe authors maintain a GitHub repository (LLM4IR) to collect relevant papers and resources about applying LLMs for IR tasks.\\n\\nSummary: Okay, here's a student-friendly summary of the research paper, focusing on the key aspects and using clear, simple language:\\n\\n**1. Title:** Large Language Models for Information Retrieval: A Survey\\n\\n**2. Problem:** Traditional search engines (Information Retrieval or IR systems) struggle with understanding the real meaning behind search queries, dealing with limited training data, and giving accurate answers. They need a boost to become more effective.\\n\\n**3. Background / Motivation:**  Think of Google search. It's pretty good, but sometimes it misses the point or doesn't quite understand what you're *really* asking. Large Language Models (LLMs) like ChatGPT are super smart at understanding and using language. Researchers are exploring how to use these LLMs to make search engines much better. LLMs can capture the *nuances* of language, where older systems often just look for keywords.\\n\\n**4. Method / Model:** This paper is a *survey*. That means it looks at a lot of different research papers and projects that are trying to combine LLMs and IR systems. It examines how LLMs can be plugged into different parts of the search process:\\n*   **Query Rewriting:** LLMs rephrase your search query to make it clearer for the search engine.\\n*   **Retrieval:** LLMs help the system find the most relevant documents in the first place.\\n*   **Reranking:** LLMs re-order the search results to put the best ones at the top.\\n*   **Reading/Summarization:** LLMs read the retrieved documents and create short summaries for you.\\n*   **Search Agents:** LLMs can act as autonomous agents that handle a variety of search tasks.\\n\\n**5. Dataset / Inputs:** This is a survey paper, so there's no single dataset. However, the papers it reviews use standard information retrieval datasets (e.g., collections of web pages, scientific articles, etc.) and user queries. The *input* to these combined systems is typically a user's search query.\\n\\n**6. Results:** This is a survey, so there is no single result. However, the survey highlights that LLMs *do* show promise in improving search results. For example, using LLMs to rewrite queries or re-rank documents often leads to more relevant results compared to traditional methods. The effectiveness depends on the specific task and how the LLM is integrated.\\n\\n**7. Strengths:**\\n*   **Clear Overview:** Provides a good overview of how LLMs are being used in different parts of the information retrieval process.\\n*   **Comprehensive:** Covers query rewriting, retrieval, re-ranking, reading/summarization, and the emerging area of search agents.\\n*   **Practical Focus:** Highlights the practical applications of LLMs for improving search.\\n*   **LLM4IR Repository**: The authors are actively curating a GitHub repository which is a useful resource.\\n\\n**8. Limitations:**\\n*   **Rapidly Evolving Field:** The field is changing *very* quickly. So some of the specific techniques discussed might become outdated fast.\\n*   **Cost & Efficiency:** LLMs can be computationally expensive, which can be a problem for large-scale search engines. The survey acknowledges that efficiency is crucial for IR systems.\\n*   **Bias and Fairness:** Like any AI system, LLMs can have biases that affect search results. This is an ongoing challenge.\\n\\n**9. Key Takeaways:**\\n\\n*   LLMs are powerful tools for understanding and generating language.\\n*   They can be used to improve various parts of the information retrieval process.\\n*   Query rewriting, retrieval, and re-ranking are key areas where LLMs can help.\\n*   Search agents are an emerging area with the potential for more automated search experiences.\\n*   Efficiency and cost are important considerations when using LLMs in search engines.\\n*   Bias in LLMs is a concern that needs to be addressed.\\n*   This is an active research area with lots of ongoing development.\\n*   LLMs can understand semantic relationships between queries and documents\\n\\n**10. Overall Conclusion:**\\n\\nThis survey shows that Large Language Models have the potential to significantly improve search engines and information retrieval systems. By using LLMs in different ways, researchers are making progress towards search engines that are better at understanding what we're really looking for and giving us more relevant and accurate results. However, there are still challenges to overcome, such as the computational cost and potential biases of LLMs. As LLMs continue to evolve, we can expect to see even more innovative ways to use them in search and information retrieval.\\n\"}, 'name': 'evaluator'}}], 'role': 'model'}, 'finish_reason': 'STOP', 'usage_metadata': {'candidates_token_count': 1379, 'candidates_tokens_details': [{'modality': 'TEXT', 'token_count': 1379}], 'prompt_token_count': 11085, 'prompt_tokens_details': [{'modality': 'TEXT', 'token_count': 11085}], 'total_token_count': 12464, 'traffic_type': 'ON_DEMAND'}, 'avg_logprobs': -0.004453893845456506, 'invocation_id': 'e-6c079805-1a85-40d7-83b0-829f404e126f', 'author': 'research_analyst', 'actions': {'state_delta': {}, 'artifact_delta': {}, 'requested_auth_configs': {}, 'requested_tool_confirmations': {}}, 'long_running_tool_ids': [], 'id': 'c642dc3a-48fb-4c0d-8734-41ea1ac8021d', 'timestamp': 1763439453.092481}\n",
            "{'content': {'parts': [{'function_response': {'id': 'adk-51398de8-f309-48ac-8d3a-97ce72e6c698', 'name': 'evaluator', 'response': {'result': \"Here's my evaluation of the summary:\\n\\n*   **Technical Correctness:** Accurate and doesn't misrepresent the paper's content.\\n*   **Clarity:** Very clear and well-written for a student audience. The use of analogies (e.g., Google search) is helpful.\\n*   **Completeness:** Covers all the key aspects of the survey paper, including the problem, methods, results, strengths, limitations, and key takeaways. The inclusion of the LLM4IR repository is a nice touch.\\n\"}}}], 'role': 'user'}, 'invocation_id': 'e-6c079805-1a85-40d7-83b0-829f404e126f', 'author': 'research_analyst', 'actions': {'state_delta': {}, 'artifact_delta': {}, 'requested_auth_configs': {}, 'requested_tool_confirmations': {}}, 'id': '7520e639-2872-4fed-b954-b9a7703e354b', 'timestamp': 1763439465.844333}\n",
            "{'model_version': 'gemini-2.0-flash', 'content': {'parts': [{'text': \"The evaluator found the summary to be technically correct, clear, and complete. There are no specific issues to address. Therefore, I will return the current summary as the final result.\\n\\n**Final Summary:**\\n\\nHere's a student-friendly summary of the research paper, focusing on the key aspects and using clear, simple language:\\n\\n**1. Title:** Large Language Models for Information Retrieval: A Survey\\n\\n**2. Problem:** Traditional search engines (Information Retrieval or IR systems) struggle with understanding the real meaning behind search queries, dealing with limited training data, and giving accurate answers. They need a boost to become more effective.\\n\\n**3. Background / Motivation:** Think of Google search. It's pretty good, but sometimes it misses the point or doesn't quite understand what you're *really* asking. Large Language Models (LLMs) like ChatGPT are super smart at understanding and using language. Researchers are exploring how to use these LLMs to make search engines much better. LLMs can capture the *nuances* of language, where older systems often just look for keywords.\\n\\n**4. Method / Model:** This paper is a *survey*. That means it looks at a lot of different research papers and projects that are trying to combine LLMs and IR systems. It examines how LLMs can be plugged into different parts of the search process:\\n\\n*   **Query Rewriting:** LLMs rephrase your search query to make it clearer for the search engine.\\n*   **Retrieval:** LLMs help the system find the most relevant documents in the first place.\\n*   **Reranking:** LLMs re-order the search results to put the best ones at the top.\\n*   **Reading/Summarization:** LLMs read the retrieved documents and create short summaries for you.\\n*   **Search Agents:** LLMs can act as autonomous agents that handle a variety of search tasks.\\n\\n**5. Dataset / Inputs:** This is a survey paper, so there's no single dataset. However, the papers it reviews use standard information retrieval datasets (e.g., collections of web pages, scientific articles, etc.) and user queries. The *input* to these combined systems is typically a user's search query.\\n\\n**6. Results:** This is a survey, so there is no single result. However, the survey highlights that LLMs *do* show promise in improving search results. For example, using LLMs to rewrite queries or re-rank documents often leads to more relevant results compared to traditional methods. The effectiveness depends on the specific task and how the LLM is integrated.\\n\\n**7. Strengths:**\\n\\n*   **Clear Overview:** Provides a good overview of how LLMs are being used in different parts of the information retrieval process.\\n*   **Comprehensive:** Covers query rewriting, retrieval, re-ranking, reading/summarization, and the emerging area of search agents.\\n*   **Practical Focus:** Highlights the practical applications of LLMs for improving search.\\n*   **LLM4IR Repository**: The authors are actively curating a GitHub repository which is a useful resource.\\n\\n**8. Limitations:**\\n\\n*   **Rapidly Evolving Field:** The field is changing *very* quickly. So some of the specific techniques discussed might become outdated fast.\\n*   **Cost & Efficiency:** LLMs can be computationally expensive, which can be a problem for large-scale search engines. The survey acknowledges that efficiency is crucial for IR systems.\\n*   **Bias and Fairness:** Like any AI system, LLMs can have biases that affect search results. This is an ongoing challenge.\\n\\n**9. Key Takeaways:**\\n\\n*   LLMs are powerful tools for understanding and generating language.\\n*   They can be used to improve various parts of the information retrieval process.\\n*   Query rewriting, retrieval, and re-ranking are key areas where LLMs can help.\\n*   Search agents are an emerging area with the potential for more automated search experiences.\\n*   Efficiency and cost are important considerations when using LLMs in search engines.\\n*   Bias in LLMs is a concern that needs to be addressed.\\n*   This is an active research area with lots of ongoing development.\\n*   LLMs can understand semantic relationships between queries and documents\\n\\n**10. Overall Conclusion:**\\n\\nThis survey shows that Large Language Models have the potential to significantly improve search engines and information retrieval systems. By using LLMs in different ways, researchers are making progress towards search engines that are better at understanding what we're really looking for and giving us more relevant and accurate results. However, there are still challenges to overcome, such as the computational cost and potential biases of LLMs. As LLMs continue to evolve, we can expect to see even more innovative ways to use them in search and information retrieval.\\n\"}], 'role': 'model'}, 'finish_reason': 'STOP', 'usage_metadata': {'candidates_token_count': 997, 'candidates_tokens_details': [{'modality': 'TEXT', 'token_count': 997}], 'prompt_token_count': 12576, 'prompt_tokens_details': [{'modality': 'TEXT', 'token_count': 12576}], 'total_token_count': 13573, 'traffic_type': 'ON_DEMAND'}, 'avg_logprobs': -0.006267424213252551, 'invocation_id': 'e-6c079805-1a85-40d7-83b0-829f404e126f', 'author': 'research_analyst', 'actions': {'state_delta': {}, 'artifact_delta': {}, 'requested_auth_configs': {}, 'requested_tool_confirmations': {}}, 'id': '42c2b243-5eee-47cc-a15c-8ffbd04ee694', 'timestamp': 1763439465.93194}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Deleting Resources Created"
      ],
      "metadata": {
        "id": "Ha90DCkNk5tr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from vertexai import agent_engines\n",
        "import vertexai\n",
        "\n",
        "vertexai.init(project=\"my-research-agent-478404\", location=\"us-west1\") #east4 also delete\n",
        "\n",
        "agents = list(agent_engines.list())\n",
        "for a in agents:\n",
        "    print(\"Deleting:\", a.resource_name)\n",
        "    agent_engines.delete(a.resource_name, force=True)\n"
      ],
      "metadata": {
        "id": "bzz-rEbkioW8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}